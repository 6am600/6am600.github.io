
<!DOCTYPE html><html lang="zh-CN" data-theme="dark">

<head>
  <meta charset="utf-8">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.33.1" theme-name="Stellar" theme-version="1.33.1">
  
  
  <meta name="generator" content="Hexo 8.1.1">
  <meta http-equiv='x-dns-prefetch-control' content='on' />
  
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#000">
  <meta name="theme-color" content="#f9fafb">
  <title>Prompt Tuning - 扳布屋</title>

  
    <meta name="description" content="讲讲提示词微调">
<meta property="og:type" content="article">
<meta property="og:title" content="Prompt Tuning">
<meta property="og:url" content="https://bambooo.top/2024/10/11/prompttuning/">
<meta property="og:site_name" content="扳布屋">
<meta property="og:description" content="讲讲提示词微调">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/avatar.jpg">
<meta property="article:published_time" content="2024-10-11T02:38:58.000Z">
<meta property="article:modified_time" content="2025-11-26T01:58:48.555Z">
<meta property="article:author" content="Bamboo">
<meta property="article:tag" content="tuning">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/avatar.jpg">
  
  
  
  <meta name="keywords" content="tuning">

  <!-- feed -->
  

  <link rel="stylesheet" href="/css/main.css?v=1.33.1">


  
    <link rel="shortcut icon" href="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/sun.png">
  

  

  <script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Bamboo","sameAs":[],"image":"https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/avatar.jpg"},"dateCreated":"2024-10-11T10:38:58+08:00","dateModified":"2025-11-26T09:58:48+08:00","datePublished":"2024-10-11T10:38:58+08:00","description":"","headline":"Prompt Tuning","mainEntityOfPage":{"@type":"WebPage","@id":"https://bambooo.top/2024/10/11/prompttuning/"},"publisher":{"@type":"Organization","name":"Bamboo","sameAs":[],"image":"https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/avatar.jpg","logo":{"@type":"ImageObject","url":"https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/avatar.jpg"}},"url":"https://bambooo.top/2024/10/11/prompttuning/","keywords":"tuning","thumbnailUrl":"https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/clipboard-image-1763683273.png","image":1}</script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lxgw-wenkai-lite-webfont@1.1.0/style.css" /><script>
  if (window.localStorage.getItem('ZYI_Theme_Mode')==='dark' || (window.localStorage.getItem('ZYI_Theme_Mode')==='Moss' && window.matchMedia('(prefers-color-scheme: dark)').matches)){
      document.querySelector("html").id = "ZYDark";
  }
</script>
<link rel="stylesheet" href="/custom/css/BBDark.css"><link rel="stylesheet" href="/custom/css/ai-summary.css"><link rel="stylesheet" href="/custom/css/news-loader.css"><link rel="stylesheet" href="/custom/css/list-style.css">
</head>
<body>

<div class="l_body content" id="start" layout="post" type="tech" ><aside class="l_left"><div class="sidebg"></div><div class="leftbar-container">


<header class="header"><div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/avatar.jpg" onerror="javascript:this.classList.add('error');this.src='https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/image/2659360.svg';"></a><a class="title" href="/"><div class="main">扳布屋</div><div class="sub normal cap">纵有疾风起</div><div class="sub hover cap" style="opacity:0"> 人生不言弃</div></a></div></header>

<div class="nav-area">

<nav class="menu dis-select"><a class="nav-item active" title="博客" href="/" style="color:##7f7f80"><span>博客</span></a><a class="nav-item" title="文档" href="/wiki/" style="color:##7f7f80"><span>文档</span></a><a class="nav-item" title="探索" href="/explore/" style="color:##7f7f80"><span>探索</span></a><a class="nav-item" title="社交" href="/friends/" style="color:##7f7f80"><span>社交</span></a></nav>
</div>
<div class="widgets">
<div class="search-wrapper" id="search-wrapper"><form class="search-form"><a class="search-button" onclick="document.getElementById(&quot;search-input&quot;).focus();"><svg t="1705074644177" viewBox="0 0 1025 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1560" width="200" height="200"><path d="M1008.839137 935.96571L792.364903 719.491476a56.783488 56.783488 0 0 0-80.152866 0 358.53545 358.53545 0 1 1 100.857314-335.166073 362.840335 362.840335 0 0 1-3.689902 170.145468 51.248635 51.248635 0 1 0 99.217358 26.444296 462.057693 462.057693 0 1 0-158.255785 242.303546l185.930047 185.725053a51.248635 51.248635 0 0 0 72.568068 0 51.248635 51.248635 0 0 0 0-72.978056z" p-id="1561"></path><path d="M616.479587 615.969233a50.428657 50.428657 0 0 0-61.498362-5.534852 174.655348 174.655348 0 0 1-177.525271 3.484907 49.403684 49.403684 0 0 0-58.833433 6.76482l-3.074918 2.869923a49.403684 49.403684 0 0 0 8.609771 78.10292 277.767601 277.767601 0 0 0 286.992355-5.739847 49.403684 49.403684 0 0 0 8.404776-76.667958z" p-id="1562"></path></svg></a><input type="text" class="search-input" id="search-input" placeholder="站内搜索"></form><div id="search-result"></div><div class="search-no-result">没有找到内容！</div></div>



<widget class="widget-wrapper recent post-list"><div class="widget-header dis-select"><span class="name">最近更新</span></div><div class="widget-body fs14"><a class="item title" href="/2025/10/11/fft&lora/"><span class="title">通俗理解全量微调和LoRA微调</span></a><a class="item title" href="/2024/10/11/prompttuning/"><span class="title">Prompt Tuning</span></a><a class="item title" href="/2025/11/24/aisummary/"><span class="title">文章添加AI摘要</span></a><a class="item title" href="/2024/01/10/nicetools/"><span class="title">好用的工具</span></a><a class="item title" href="/2025/03/27/decodeapk/"><span class="title">反编译 APK</span></a><a class="item title" href="/2025/10/20/fctomcp/"><span class="title">从Function Call 到 MCP</span></a><a class="item title" href="/2025/05/12/noteupgrade/"><span class="title">Note标签美化</span></a><a class="item title" href="/2025/05/01/hinttool/"><span class="title">Hexo-tag-hint</span></a><a class="item title" href="/2025/04/02/BM25/"><span class="title">BM25算法</span></a><a class="item title" href="/2025/03/20/flashattn/"><span class="title">Flash Attention</span></a></div></widget>
</div>
<footer class="footer dis-select"><div class="social-wrap"><a class="social" href="https://music.163.com/#/user/home?id=1385723260" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder/social/3845874.svg"/></a><a class="social" href="javascript:util.scrollTop()" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="1.5"><path stroke-linejoin="round" d="m9 15.5l3-3l3 3m-6-4l3-3l3 3"></path><path d="M7 3.338A9.95 9.95 0 0 1 12 2c5.523 0 10 4.477 10 10s-4.477 10-10 10S2 17.523 2 12c0-1.821.487-3.53 1.338-5"></path></g></svg></a><a class="social" href="javaScript:void('永夜');" rel="noopener noreferrer"><img id="ThemeM" src="https://upyun.thatcdn.cn/public/img/icon/Moon.png"/></a><a class="social" href="javaScript:void('永昼');" rel="noopener noreferrer"><img id="ThemeL" src="https://upyun.thatcdn.cn/public/img/icon/Sun.png"/></a><a class="social" href="javaScript:void('跟随系统');" rel="noopener noreferrer"><img id="ThemeAI" src="https://upyun.thatcdn.cn/public/img/icon/AI.png"/></a></div></footer>
</div></aside><div class="l_main" id="main">





<div class="article banner top"><img class="lazy bg" data-src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/clipboard-image-1763683273.png">
  <div class="content">
    <div class="top bread-nav footnote"><div class="left"><div class="flex-row" id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a>
<span class="sep"></span><a class="cap breadcrumb" href="/">文章</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/%E6%8F%90%E7%A4%BA%E8%AF%8D/">提示词</a> <span class="sep"></span> <a class="cap breadcrumb-link" href="/categories/%E6%8F%90%E7%A4%BA%E8%AF%8D/%E5%BE%AE%E8%B0%83/">微调</a> <span class="sep"></span> <a class="cap breadcrumb-link" href="/categories/%E6%8F%90%E7%A4%BA%E8%AF%8D/%E5%BE%AE%E8%B0%83/Tuning/">Tuning</a></div>
<div class="flex-row" id="post-meta"><span class="text created">发布于：<time datetime="2024-10-11T02:38:58.000Z">2024-10-11</time></span><span class="sep updated"></span><span class="text updated">更新于：<time datetime="2025-11-26T01:58:48.555Z">2025-11-26</time></span></div></div></div>
    
    <div class="bottom only-title">
      
      <div class="text-area">
        <h1 class="text title"><span>Prompt Tuning</span></h1>
        
      </div>
    </div>
    
  </div>
  </div><article class="md-text content"><div class="ai-summary">
    <div class="ai-summary-header">
        <div class="ai-head-left">
        </div>
        <a class="ai-about" href="/2025/11/24/aisummary/">关于AI</a>
    </div>

    <div class="ai-explanation" style="display: block;" data-summary="这里是扳布AI，这篇文章主要介绍了NLP任务演进的四种范式及其核心技术。从基于传统机器学习的第一范式，到深度学习的第二范式，再到预训练模型微调的第三范式，最终发展到当前主流的基于Prompt的第四范式。文章重点解析了Prompt-Tuning的工作原理，包括构建模板和标签词映射的步骤，并对比了Fine-Tuning的差异。同时，详细梳理了Prompt-Tuning的发展历程，从GPT3的In-context Learning到PET模型的PVP框架，再到区分Hard Prompt与Soft Prompt的优化方法。此外，还涵盖了PEFT参数高效微调技术，如Adapter Tuning、LoRA及其变种，展现了NLP技术向更高精度、更少监督方向发展的趋势。">
        <!-- 这里是扳布AI，这篇文章主要介绍了NLP任务演进的四种范式及其核心技术。从基于传统机器学习的第一范式，到深度学习的第二范式，再到预训练模型微调的第三范式，最终发展到当前主流的基于Prompt的第四范式。文章重点解析了Prompt-Tuning的工作原理，包括构建模板和标签词映射的步骤，并对比了Fine-Tuning的差异。同时，详细梳理了Prompt-Tuning的发展历程，从GPT3的In-context Learning到PET模型的PVP框架，再到区分Hard Prompt与Soft Prompt的优化方法。此外，还涵盖了PEFT参数高效微调技术，如Adapter Tuning、LoRA及其变种，展现了NLP技术向更高精度、更少监督方向发展的趋势。 -->
    </div>

    <div class="ai-title">
        <div class="ai-title-left">
            <!-- 图标已替换为你要求的 Hexo icon 插件写法 -->
            <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" d="M20 12a8 8 0 1 1-16 0a8 8 0 0 1 16 0" opacity=".5"/><path fill="currentColor" d="M17.712 5.453c1.047-.193 2.006-.259 2.797-.152c.77.103 1.536.393 1.956 1.064c.446.714.312 1.542-.012 2.258c-.33.728-.918 1.499-1.672 2.268c-1.516 1.547-3.836 3.226-6.597 4.697c-2.763 1.472-5.495 2.484-7.694 2.92c-1.095.217-2.098.299-2.923.201c-.8-.095-1.6-.383-2.032-1.075c-.47-.752-.296-1.63.07-2.379c.375-.768 1.032-1.586 1.872-2.403L4 12.416c0 .219.083.71.168 1.146c.045.23.09.444.123.596c-.652.666-1.098 1.263-1.339 1.756c-.277.567-.208.825-.145.925c.072.116.305.305.937.38c.609.073 1.44.018 2.455-.183c2.02-.4 4.613-1.351 7.28-2.772c2.667-1.42 4.85-3.015 6.23-4.423c.694-.707 1.15-1.334 1.377-1.836c.233-.515.167-.75.107-.844c-.07-.112-.289-.294-.883-.374c-.542-.072-1.272-.041-2.163.112L16.87 5.656c.338-.101.658-.17.842-.203"/></svg>
            <div class="ai-title-text">
                扳布的AI摘要
            </div>
        </div>

        <div class="ai-tag" id="ai-tag">
            HunYuan-turbos
        </div>
    </div>
</div>
<link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><blockquote>
<p>文中部分内容参考：<a target="_blank" rel="noopener" href="https://wjn1996.blog.csdn.net/article/details/120607050">https://wjn1996.blog.csdn.net/article/details/120607050</a></p>
<p>在说明什么是Prompt Tuning之前，先简单了解下NLP任务四范式</p>
</blockquote>
<h2 id="NLP任务四种范式"><a href="#NLP任务四种范式" class="headerlink" title="NLP任务四种范式"></a>NLP任务四种范式</h2><div class="tag-plugin timeline"><div class="timenode" index="0"><div class="header"><span>第一范式</span></div><div class="body fs14"><p>基于「传统机器学习模型」的范式，如TF-IDF特征+朴素贝叶斯等机器算法</p></div></div><div class="timenode" index="1"><div class="header"><span>第二范式</span></div><div class="body fs14"><p>基于「深度学习模型」的范式，如word2vec特征+LSTM等深度学习算法，相比于第一范式，模型准确有所提高，特征工程的工作也有所减少</p></div></div><div class="timenode" index="2"><div class="header"><span>第三范式</span></div><div class="body fs14"><p>基于「预训练模型+fine-tuning」的范式，如Bert+fine-tuning的NLP任务，相比于第二范式，模型准确度显著提高，模型也随之变得更大，但小数据集就可训练出好模型</p></div></div><div class="timenode" index="3"><div class="header"><span>第四范式</span></div><div class="body fs14"><p>基于「预训练模型+Prompt+预测」的范式，如Bert+Prompt的范式相比于第三范式，模型训练所需的训练数据显著减少</p></div></div></div>
<p>在整个NLP领域，整个发展历史都是朝着精度更高、少监督甚至无监督的方向发展，而 Prompt-Tuning 是目前学术界向这个方向进军最新也是最火的研究成果</p>
<h2 id="Fine-Tuning"><a href="#Fine-Tuning" class="headerlink" title="Fine-Tuning"></a>Fine-Tuning</h2><blockquote>
<p>简单回顾下Fine-Tuning</p>
</blockquote>
<p>Fine-Tuning属于一种迁移学习方式，在自然语言处理（NLP）中，Fine-Tuning是用于将预训练的语言模型适应于特定任务或领域。Fine-Tuning的基本思想是采用已经在大量文本上进行训练的预训练语言模型，然后在小规模的任务特定文本上继续训练它</p>
<div class="tag-plugin image"><div class="image-bg" style="aspect-ratio:924/509;"><img class="lazy" src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251121081035980.png" data-src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251121081035980.png" data-fancybox="true"onerror="this.src=&quot;data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='2rem' height='2rem' viewBox='0 0 24 24'%3E%3C!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --%3E%3Cpath fill='%23F44336' d='M22 12.698c-.002 1.47-.013 2.718-.096 3.743c-.097 1.19-.296 2.184-.74 3.009a4.2 4.2 0 0 1-.73.983c-.833.833-1.893 1.21-3.237 1.39C15.884 22 14.2 22 12.053 22h-.106c-2.148 0-3.83 0-5.144-.177c-1.343-.18-2.404-.557-3.236-1.39c-.738-.738-1.12-1.656-1.322-2.795c-.2-1.12-.236-2.512-.243-4.241Q1.999 12.737 2 12v-.054c0-2.148 0-3.83.177-5.144c.18-1.343.557-2.404 1.39-3.236s1.893-1.21 3.236-1.39c1.168-.157 2.67-.175 4.499-.177a.697.697 0 1 1 0 1.396c-1.855.002-3.234.018-4.313.163c-1.189.16-1.906.464-2.436.994S3.72 5.8 3.56 6.99C3.397 8.2 3.395 9.788 3.395 12v.784l.932-.814a2.14 2.14 0 0 1 2.922.097l3.99 3.99a1.86 1.86 0 0 0 2.385.207l.278-.195a2.79 2.79 0 0 1 3.471.209l2.633 2.37c.265-.557.423-1.288.507-2.32c.079-.972.09-2.152.091-3.63a.698.698 0 0 1 1.396 0' opacity='.5'/%3E%3Cpath fill='%23F44336' fill-rule='evenodd' d='M17.5 11c-2.121 0-3.182 0-3.841-.659S13 8.621 13 6.5s0-3.182.659-3.841S15.379 2 17.5 2s3.182 0 3.841.659S22 4.379 22 6.5s0 3.182-.659 3.841S19.621 11 17.5 11m-1.47-7.03a.75.75 0 1 0-1.06 1.06l1.47 1.47l-1.47 1.47a.75.75 0 0 0 1.06 1.06l1.47-1.47l1.47 1.47a.75.75 0 1 0 1.06-1.06L18.56 6.5l1.47-1.47a.75.75 0 0 0-1.06-1.06L17.5 5.44z' clip-rule='evenodd'/%3E%3C/svg%3E&quot;"/><div class="lazy-icon" style="background-image:url(https://api.iconify.design/eos-icons:three-dots-loading.svg?color=%231cd0fd);"></div></div></div>
<p>这种方式的痛点在于：</p>
<ul>
<li>下游任务的目标和预训练的目标差距过大，可能导致过拟合</li>
<li>微调过程需要依赖大量监督语料</li>
<li>大语言模型参数量都极大，完全微调 Full Fine-Tuning 的代价很高</li>
</ul>
<p><strong>解决办法：Prompt-Tuning，通过添加模板的方法来避免引入额外的参数，从而让模型可以在小样本（few-shot）或零样本（zero-shot）场景下达到理想效果</strong></p>
<h2 id="Prompt-Tuning简述"><a href="#Prompt-Tuning简述" class="headerlink" title="Prompt-Tuning简述"></a>Prompt-Tuning简述</h2><p>基于Fine-Tuning的方法是让预训练模型去迁就下游任务，而基于Prompt-Tuning的方法可以让下游任务去迁就预训练模型，其目的是将Fine-Tuning的下游任务目标转换为Pre-training的任务</p>
<div class="tag-plugin image"><div class="image-bg" style="aspect-ratio:940/607;"><img class="lazy" src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251121081720602.png" data-src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251121081720602.png" data-fancybox="true"onerror="this.src=&quot;data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='2rem' height='2rem' viewBox='0 0 24 24'%3E%3C!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --%3E%3Cpath fill='%23F44336' d='M22 12.698c-.002 1.47-.013 2.718-.096 3.743c-.097 1.19-.296 2.184-.74 3.009a4.2 4.2 0 0 1-.73.983c-.833.833-1.893 1.21-3.237 1.39C15.884 22 14.2 22 12.053 22h-.106c-2.148 0-3.83 0-5.144-.177c-1.343-.18-2.404-.557-3.236-1.39c-.738-.738-1.12-1.656-1.322-2.795c-.2-1.12-.236-2.512-.243-4.241Q1.999 12.737 2 12v-.054c0-2.148 0-3.83.177-5.144c.18-1.343.557-2.404 1.39-3.236s1.893-1.21 3.236-1.39c1.168-.157 2.67-.175 4.499-.177a.697.697 0 1 1 0 1.396c-1.855.002-3.234.018-4.313.163c-1.189.16-1.906.464-2.436.994S3.72 5.8 3.56 6.99C3.397 8.2 3.395 9.788 3.395 12v.784l.932-.814a2.14 2.14 0 0 1 2.922.097l3.99 3.99a1.86 1.86 0 0 0 2.385.207l.278-.195a2.79 2.79 0 0 1 3.471.209l2.633 2.37c.265-.557.423-1.288.507-2.32c.079-.972.09-2.152.091-3.63a.698.698 0 0 1 1.396 0' opacity='.5'/%3E%3Cpath fill='%23F44336' fill-rule='evenodd' d='M17.5 11c-2.121 0-3.182 0-3.841-.659S13 8.621 13 6.5s0-3.182.659-3.841S15.379 2 17.5 2s3.182 0 3.841.659S22 4.379 22 6.5s0 3.182-.659 3.841S19.621 11 17.5 11m-1.47-7.03a.75.75 0 1 0-1.06 1.06l1.47 1.47l-1.47 1.47a.75.75 0 0 0 1.06 1.06l1.47-1.47l1.47 1.47a.75.75 0 1 0 1.06-1.06L18.56 6.5l1.47-1.47a.75.75 0 0 0-1.06-1.06L17.5 5.44z' clip-rule='evenodd'/%3E%3C/svg%3E&quot;"/><div class="lazy-icon" style="background-image:url(https://api.iconify.design/eos-icons:three-dots-loading.svg?color=%231cd0fd);"></div></div></div>
<h3 id="工作过程"><a href="#工作过程" class="headerlink" title="工作过程"></a>工作过程</h3><p>定义一个句子：[CLS] I like the Disney films very much. [SEP]</p>
<p>传统的Fine-tuning方法: 将其通过BERT模型获得 [CLS] 表征之后再喂入新增加的MLP分类器进行二分类，预测该句子是积极的（positive）还是消极的（negative），因此需要一定量的训练数据来训练</p>
<p><strong>Prompt-tuning执行步骤：</strong></p>
<ul>
<li><strong>构建模板：</strong> (Template)生成与给定句子相关的一个含有[MASK]标记的模板. 例如It was [MASK], 并拼接到原始的文本中，获得Prompt-Tuning的输入：[CLS] I like the Disney films very much. [SEP] It was [MASK]. [SEP]，将其喂入BERT模型中，并复用预训练好的MLM分类器，即可直接得到[MASK]预测的各个token的概率分布</li>
<li><strong>标签词映射：</strong> (Verbalizer)因为[MASK]只对部分词感兴趣，因此需要建立一个映射关系. 例如如果[MASK]预测的词是“great”，则认为是positive类，如果是“terrible”，则认为是negative类</li>
<li><strong>训练：</strong>根据Verbalizer，则可以获得指定label word的预测概率分布，并采用交叉信息熵进行训练。此时因为只对预训练好的MLM head进行微调，所以避免了过拟合问题</li>
</ul>
<h3 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h3><p>不同的任务应该有不同的template和label word，因此如何最大化的寻找当前任务更加合适的template和labelword是Prompt-tuning非常重要的挑战</p>
<div class="tag-plugin image"><div class="image-bg" style="aspect-ratio:4952/1764;"><img class="lazy" src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251121084256456.png" data-src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251121084256456.png" data-fancybox="true"onerror="this.src=&quot;data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='2rem' height='2rem' viewBox='0 0 24 24'%3E%3C!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --%3E%3Cpath fill='%23F44336' d='M22 12.698c-.002 1.47-.013 2.718-.096 3.743c-.097 1.19-.296 2.184-.74 3.009a4.2 4.2 0 0 1-.73.983c-.833.833-1.893 1.21-3.237 1.39C15.884 22 14.2 22 12.053 22h-.106c-2.148 0-3.83 0-5.144-.177c-1.343-.18-2.404-.557-3.236-1.39c-.738-.738-1.12-1.656-1.322-2.795c-.2-1.12-.236-2.512-.243-4.241Q1.999 12.737 2 12v-.054c0-2.148 0-3.83.177-5.144c.18-1.343.557-2.404 1.39-3.236s1.893-1.21 3.236-1.39c1.168-.157 2.67-.175 4.499-.177a.697.697 0 1 1 0 1.396c-1.855.002-3.234.018-4.313.163c-1.189.16-1.906.464-2.436.994S3.72 5.8 3.56 6.99C3.397 8.2 3.395 9.788 3.395 12v.784l.932-.814a2.14 2.14 0 0 1 2.922.097l3.99 3.99a1.86 1.86 0 0 0 2.385.207l.278-.195a2.79 2.79 0 0 1 3.471.209l2.633 2.37c.265-.557.423-1.288.507-2.32c.079-.972.09-2.152.091-3.63a.698.698 0 0 1 1.396 0' opacity='.5'/%3E%3Cpath fill='%23F44336' fill-rule='evenodd' d='M17.5 11c-2.121 0-3.182 0-3.841-.659S13 8.621 13 6.5s0-3.182.659-3.841S15.379 2 17.5 2s3.182 0 3.841.659S22 4.379 22 6.5s0 3.182-.659 3.841S19.621 11 17.5 11m-1.47-7.03a.75.75 0 1 0-1.06 1.06l1.47 1.47l-1.47 1.47a.75.75 0 0 0 1.06 1.06l1.47-1.47l1.47 1.47a.75.75 0 1 0 1.06-1.06L18.56 6.5l1.47-1.47a.75.75 0 0 0-1.06-1.06L17.5 5.44z' clip-rule='evenodd'/%3E%3C/svg%3E&quot;"/><div class="lazy-icon" style="background-image:url(https://api.iconify.design/eos-icons:three-dots-loading.svg?color=%231cd0fd);"></div></div></div>
<h2 id="Prompt-Tuning发展历程"><a href="#Prompt-Tuning发展历程" class="headerlink" title="Prompt-Tuning发展历程"></a>Prompt-Tuning发展历程</h2><h3 id="鼻祖-——-GPT3"><a href="#鼻祖-——-GPT3" class="headerlink" title="鼻祖 —— GPT3"></a>鼻祖 —— GPT3</h3><p>GPT-3开创性的提出了<code>In-context Learning</code>的思想. 即无需修改模型即可实现few-shot、zero-shot的learning. 同时引入了Demonstrate Learning, 即让模型知道与标签相似的语义描述，提升推理能力</p>
<div class="tag-plugin image"><div class="image-bg" style="aspect-ratio:1045/568;"><img class="lazy" src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251121085259159.png" data-src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251121085259159.png" data-fancybox="true"onerror="this.src=&quot;data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='2rem' height='2rem' viewBox='0 0 24 24'%3E%3C!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --%3E%3Cpath fill='%23F44336' d='M22 12.698c-.002 1.47-.013 2.718-.096 3.743c-.097 1.19-.296 2.184-.74 3.009a4.2 4.2 0 0 1-.73.983c-.833.833-1.893 1.21-3.237 1.39C15.884 22 14.2 22 12.053 22h-.106c-2.148 0-3.83 0-5.144-.177c-1.343-.18-2.404-.557-3.236-1.39c-.738-.738-1.12-1.656-1.322-2.795c-.2-1.12-.236-2.512-.243-4.241Q1.999 12.737 2 12v-.054c0-2.148 0-3.83.177-5.144c.18-1.343.557-2.404 1.39-3.236s1.893-1.21 3.236-1.39c1.168-.157 2.67-.175 4.499-.177a.697.697 0 1 1 0 1.396c-1.855.002-3.234.018-4.313.163c-1.189.16-1.906.464-2.436.994S3.72 5.8 3.56 6.99C3.397 8.2 3.395 9.788 3.395 12v.784l.932-.814a2.14 2.14 0 0 1 2.922.097l3.99 3.99a1.86 1.86 0 0 0 2.385.207l.278-.195a2.79 2.79 0 0 1 3.471.209l2.633 2.37c.265-.557.423-1.288.507-2.32c.079-.972.09-2.152.091-3.63a.698.698 0 0 1 1.396 0' opacity='.5'/%3E%3Cpath fill='%23F44336' fill-rule='evenodd' d='M17.5 11c-2.121 0-3.182 0-3.841-.659S13 8.621 13 6.5s0-3.182.659-3.841S15.379 2 17.5 2s3.182 0 3.841.659S22 4.379 22 6.5s0 3.182-.659 3.841S19.621 11 17.5 11m-1.47-7.03a.75.75 0 1 0-1.06 1.06l1.47 1.47l-1.47 1.47a.75.75 0 0 0 1.06 1.06l1.47-1.47l1.47 1.47a.75.75 0 1 0 1.06-1.06L18.56 6.5l1.47-1.47a.75.75 0 0 0-1.06-1.06L17.5 5.44z' clip-rule='evenodd'/%3E%3C/svg%3E&quot;"/><div class="lazy-icon" style="background-image:url(https://api.iconify.design/eos-icons:three-dots-loading.svg?color=%231cd0fd);"></div></div></div>
<p>这种方法存在一些问题：</p>
<ul>
<li>其建立在超大规模预训练语言模型上，模型参数量通常超过10B，在真实场景中很难应用</li>
<li>该方法应用于参数规模小的模型时，效果会下降很多，因此后续提出Prompt-Tuning</li>
<li>GPT3中提供的prompt过于简单，泛化性能低</li>
</ul>
<p>因此，PET模型问世</p>
<h3 id="PET模型"><a href="#PET模型" class="headerlink" title="PET模型"></a>PET模型</h3><blockquote>
<p>PET（Pattern-Exploiting Training）出自《Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference》（EACL2021），根据论文题目则可以看出，Prompt-Tuning启发于文本分类任务，并且试图将所有的分类任务转换为与MLM一致的完形填空.</p>
</blockquote>
<p>PET模型设计了两个很重要的组件 → Pattern、Verbalizer 简称PVP（Pattern-Verbalizer-Pair）</p>
<ul>
<li>Pattern（Template）: 记作T, 即上文提到的Template，其为额外添加的带有[mask]标记的短文本，通常一个样本只有一个Pattern, 由于不同的任务、不同的样本可能会有其更加合适的pattern，<strong>因此如何构建合适的pattern是Prompt-Tuning的研究点之一</strong></li>
<li>Verbalizer: 记作V, 即标签词的映射，对于具体的分类任务，需要选择指定的标签词（label word）.例如情感分析中，我们期望Verbalizer可能是 （positive和negative是类标签）. 同样，不同的任务有其相应的labelword，但需要注意的是，Verbalizer的构建需要取决于对应的Pattern, <strong>因此如何构建Verbalizer是另一个研究挑战</strong></li>
</ul>
<p>目前基于PVP框架, 最需要关注的问题是如何选择或构建合适的Pattern和Verbalizer . 一种简单的方法是根据特定任务的性质和先验知识人工设计模板. 注意：在同样的数据集和训练条件下. 选择不同的Pattern和Verbalizer会产生差异很大的结果</p>
<div class="tag-plugin image"><div class="image-bg" style="aspect-ratio:396/386;"><img class="lazy" src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251125163855311.png" data-src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251125163855311.png" data-fancybox="true"onerror="this.src=&quot;data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='2rem' height='2rem' viewBox='0 0 24 24'%3E%3C!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --%3E%3Cpath fill='%23F44336' d='M22 12.698c-.002 1.47-.013 2.718-.096 3.743c-.097 1.19-.296 2.184-.74 3.009a4.2 4.2 0 0 1-.73.983c-.833.833-1.893 1.21-3.237 1.39C15.884 22 14.2 22 12.053 22h-.106c-2.148 0-3.83 0-5.144-.177c-1.343-.18-2.404-.557-3.236-1.39c-.738-.738-1.12-1.656-1.322-2.795c-.2-1.12-.236-2.512-.243-4.241Q1.999 12.737 2 12v-.054c0-2.148 0-3.83.177-5.144c.18-1.343.557-2.404 1.39-3.236s1.893-1.21 3.236-1.39c1.168-.157 2.67-.175 4.499-.177a.697.697 0 1 1 0 1.396c-1.855.002-3.234.018-4.313.163c-1.189.16-1.906.464-2.436.994S3.72 5.8 3.56 6.99C3.397 8.2 3.395 9.788 3.395 12v.784l.932-.814a2.14 2.14 0 0 1 2.922.097l3.99 3.99a1.86 1.86 0 0 0 2.385.207l.278-.195a2.79 2.79 0 0 1 3.471.209l2.633 2.37c.265-.557.423-1.288.507-2.32c.079-.972.09-2.152.091-3.63a.698.698 0 0 1 1.396 0' opacity='.5'/%3E%3Cpath fill='%23F44336' fill-rule='evenodd' d='M17.5 11c-2.121 0-3.182 0-3.841-.659S13 8.621 13 6.5s0-3.182.659-3.841S15.379 2 17.5 2s3.182 0 3.841.659S22 4.379 22 6.5s0 3.182-.659 3.841S19.621 11 17.5 11m-1.47-7.03a.75.75 0 1 0-1.06 1.06l1.47 1.47l-1.47 1.47a.75.75 0 0 0 1.06 1.06l1.47-1.47l1.47 1.47a.75.75 0 1 0 1.06-1.06L18.56 6.5l1.47-1.47a.75.75 0 0 0-1.06-1.06L17.5 5.44z' clip-rule='evenodd'/%3E%3C/svg%3E&quot;"/><div class="lazy-icon" style="background-image:url(https://api.iconify.design/eos-icons:three-dots-loading.svg?color=%231cd0fd);"></div></div></div>
<p><strong>总结人工设计方法的缺陷：</strong></p>
<ul>
<li>采用人工构建的方法成本高，需要与领域任务相关的先验知识</li>
<li>人工设计的Pattern和Verbalizer不能保证获得最优解，训练不稳定，不同的PVP对结果产生的差异明显，方差大</li>
<li>在预训练阶段MLM任务并非完全按照PVP的模式进行训练的，因此人工构建的Pattern和Verbalizer使得Prompt-Tuning与MLM在语义和分布上依然存在差异</li>
</ul>
<h3 id="Prompt-Oriented-Fine-Tuning"><a href="#Prompt-Oriented-Fine-Tuning" class="headerlink" title="Prompt-Oriented Fine-Tuning"></a>Prompt-Oriented Fine-Tuning</h3><blockquote>
<p>面向Prompt的Fine Tuning，该训练方法的本质是将目标任务转换为适应预训练模型的预训练任务，以适应预训练模型的学习体系</p>
</blockquote>
<p>以情感分析为例：</p>
<div class="tag-plugin tabs" align="center"id="tab_1"><div class="nav-tabs"><div class="tab"><a href="#tab_1-1">BERT Fine-Tuning</a></div><div class="tab active"><a href="#tab_1-2">Prompt-Oriented Fine-Tuning</a></div></div><div class="tab-content"><div class="tab-pane" id="tab_1-1"><p>Fine-Tuning流程：将训练文本经过Bert编码后，生成向量表征，再利用</p>
<p>该向量表征，连接全连接层，实现最终的情感类别识别，这种方式存在一</p>
<p>个显式的弊端：预训练任务与下游任务存在gap</p></div><div class="tab-pane active" id="tab_1-2"><p>基本流程: 构建prompt文本：It was[MASK].，将prompt文本与输入text</p>
<p>文本text = The film isattractive.拼接生成: It was[MASK].The film is attractive.，</p>
<p>输入至预训练模型中，训练任务目标和MLM任务的目标一致，即识别被[MASK]掉的词</p></div></div></div>
<blockquote>
<p>Prompt-Oriented Fine-Tuning方法中，预训练模型参数是可变的, 本质是Prompt-Tuning+Fine-Tuning的结合体. </p>
<p>该方法在Bert类相对较小的模型上表现较好，但是随着模型越来越大，如果每次针对下游任务，都需要更新预训练</p>
<p>模型的参数，资源成本及时间成本都会很高，因此后续陆续提出了不更新预训练模型参数，单纯只针对prompt进行</p>
<p>调优的方法</p>
</blockquote>
<p>针对Prompt调优方法的分类：<strong>Hard Prompt</strong> 和 <strong>Soft Prompt</strong></p>
<p>常见下游任务Prompt设计：</p>
<div class="tag-plugin image"><div class="image-bg" style="aspect-ratio:1539/465;"><img class="lazy" src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251125170002666.png" data-src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251125170002666.png" data-fancybox="true"onerror="this.src=&quot;data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='2rem' height='2rem' viewBox='0 0 24 24'%3E%3C!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --%3E%3Cpath fill='%23F44336' d='M22 12.698c-.002 1.47-.013 2.718-.096 3.743c-.097 1.19-.296 2.184-.74 3.009a4.2 4.2 0 0 1-.73.983c-.833.833-1.893 1.21-3.237 1.39C15.884 22 14.2 22 12.053 22h-.106c-2.148 0-3.83 0-5.144-.177c-1.343-.18-2.404-.557-3.236-1.39c-.738-.738-1.12-1.656-1.322-2.795c-.2-1.12-.236-2.512-.243-4.241Q1.999 12.737 2 12v-.054c0-2.148 0-3.83.177-5.144c.18-1.343.557-2.404 1.39-3.236s1.893-1.21 3.236-1.39c1.168-.157 2.67-.175 4.499-.177a.697.697 0 1 1 0 1.396c-1.855.002-3.234.018-4.313.163c-1.189.16-1.906.464-2.436.994S3.72 5.8 3.56 6.99C3.397 8.2 3.395 9.788 3.395 12v.784l.932-.814a2.14 2.14 0 0 1 2.922.097l3.99 3.99a1.86 1.86 0 0 0 2.385.207l.278-.195a2.79 2.79 0 0 1 3.471.209l2.633 2.37c.265-.557.423-1.288.507-2.32c.079-.972.09-2.152.091-3.63a.698.698 0 0 1 1.396 0' opacity='.5'/%3E%3Cpath fill='%23F44336' fill-rule='evenodd' d='M17.5 11c-2.121 0-3.182 0-3.841-.659S13 8.621 13 6.5s0-3.182.659-3.841S15.379 2 17.5 2s3.182 0 3.841.659S22 4.379 22 6.5s0 3.182-.659 3.841S19.621 11 17.5 11m-1.47-7.03a.75.75 0 1 0-1.06 1.06l1.47 1.47l-1.47 1.47a.75.75 0 0 0 1.06 1.06l1.47-1.47l1.47 1.47a.75.75 0 1 0 1.06-1.06L18.56 6.5l1.47-1.47a.75.75 0 0 0-1.06-1.06L17.5 5.44z' clip-rule='evenodd'/%3E%3C/svg%3E&quot;"/><div class="lazy-icon" style="background-image:url(https://api.iconify.design/eos-icons:three-dots-loading.svg?color=%231cd0fd);"></div></div></div>
<p><strong>模板类别：</strong></p>
<div class="tag-plugin tabs" align="center"id="tab_2"><div class="nav-tabs"><div class="tab"><a href="#tab_2-1">Hard Prompt</a></div><div class="tab active"><a href="#tab_2-2">Soft Prompt</a></div></div><div class="tab-content"><div class="tab-pane" id="tab_2-1"><p><strong>离散提示</strong>: 是一种固定的提示模板，通过将特定的关键词或短语(真实的文本字符串)</p>
<p>直接嵌入到文本中，引导模型生成符合要求的文本. </p>
<p><strong>特点</strong>: 提示模板是固定的，不能根据不同的任务和需求进行调整. </p>
<p><strong>缺陷</strong>：依赖人工，改变prompt中的单个单词会给实验结果带来巨大的差异</p></div><div class="tab-pane active" id="tab_2-2"><p><strong>连续提示</strong>：是指通过给模型输入一个可参数化的提示模板，从而引导模型生成符合</p>
<p>特定要求的文本. </p>
<p><strong>特点</strong>: 提示模板中的参数可以根据具体任务和需求进行调整，以达到最佳的生成效果. </p>
<p><strong>优点</strong>：不需要显式地指定这些模板中各个token具体是什么，而只需要在语义空间中</p>
<p>表示一个向量即可</p></div></div></div>
<h4 id="Soft-Prompt理解"><a href="#Soft-Prompt理解" class="headerlink" title="Soft Prompt理解"></a>Soft Prompt理解</h4><ul>
<li>基于Soft Prompt, 不同的任务、数据可以自适应地在语义空间中寻找若干合适的向量，来代表模板中的每一个词，相较于显式的token，这类token称为 伪标记（Pseudo Token) .下面给出基于连续提示的模板定义</li>
<li>假设针对分类任务，给定一个输入句子x，连续提示的模板可以定义为T=[x],[v1],[v2],…,[vn] [MASK]：其中[vn]则是伪标记，其仅代表一个抽象的token，并没有实际的含义，本质上是一个向量</li>
</ul>
<p>Soft Prompt方法, 是将模板变为可训练的参数，不同的样本可以在连续的向量空间中寻找合适的伪标记，同时也增加模型的泛化能力. 因此, 连续法需要引入少量的参数并在训练时进行参数更新，但预训练模型参数是不变的，变的是prompt token对应的词向量（Word Embedding）表征及其他引入的少量参数</p>
<h3 id="Prompt-Tuning（NLG任务）"><a href="#Prompt-Tuning（NLG任务）" class="headerlink" title="Prompt Tuning（NLG任务）"></a>Prompt Tuning（NLG任务）</h3><blockquote>
<p>Prompt Tuning 是2021年谷歌在论文《The Power of Scale for Parameter-Efficient Prompt Tuning》中提出的微调方法，该方法基于T5模型(最大参数11B)为每一个输入文本假设一个固定前缀提示，该提示由神经网络参数化，并在下游任务微调时进行更新，整个过程中预训练的大模型参数被冻结</p>
</blockquote>
<div class="tag-plugin grid"  style="grid-template-columns: repeat(auto-fill, minmax(240px, 1fr));"><div class="cell" style="">
    <div class="tag-plugin image"><div class="image-bg" style="aspect-ratio:1440/754;"><img class="lazy" src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251125182438128.png" data-src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251125182438128.png" data-fancybox="true"onerror="this.src=&quot;data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='2rem' height='2rem' viewBox='0 0 24 24'%3E%3C!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --%3E%3Cpath fill='%23F44336' d='M22 12.698c-.002 1.47-.013 2.718-.096 3.743c-.097 1.19-.296 2.184-.74 3.009a4.2 4.2 0 0 1-.73.983c-.833.833-1.893 1.21-3.237 1.39C15.884 22 14.2 22 12.053 22h-.106c-2.148 0-3.83 0-5.144-.177c-1.343-.18-2.404-.557-3.236-1.39c-.738-.738-1.12-1.656-1.322-2.795c-.2-1.12-.236-2.512-.243-4.241Q1.999 12.737 2 12v-.054c0-2.148 0-3.83.177-5.144c.18-1.343.557-2.404 1.39-3.236s1.893-1.21 3.236-1.39c1.168-.157 2.67-.175 4.499-.177a.697.697 0 1 1 0 1.396c-1.855.002-3.234.018-4.313.163c-1.189.16-1.906.464-2.436.994S3.72 5.8 3.56 6.99C3.397 8.2 3.395 9.788 3.395 12v.784l.932-.814a2.14 2.14 0 0 1 2.922.097l3.99 3.99a1.86 1.86 0 0 0 2.385.207l.278-.195a2.79 2.79 0 0 1 3.471.209l2.633 2.37c.265-.557.423-1.288.507-2.32c.079-.972.09-2.152.091-3.63a.698.698 0 0 1 1.396 0' opacity='.5'/%3E%3Cpath fill='%23F44336' fill-rule='evenodd' d='M17.5 11c-2.121 0-3.182 0-3.841-.659S13 8.621 13 6.5s0-3.182.659-3.841S15.379 2 17.5 2s3.182 0 3.841.659S22 4.379 22 6.5s0 3.182-.659 3.841S19.621 11 17.5 11m-1.47-7.03a.75.75 0 1 0-1.06 1.06l1.47 1.47l-1.47 1.47a.75.75 0 0 0 1.06 1.06l1.47-1.47l1.47 1.47a.75.75 0 1 0 1.06-1.06L18.56 6.5l1.47-1.47a.75.75 0 0 0-1.06-1.06L17.5 5.44z' clip-rule='evenodd'/%3E%3C/svg%3E&quot;"/><div class="lazy-icon" style="background-image:url(https://api.iconify.design/eos-icons:three-dots-loading.svg?color=%231cd0fd);"></div></div></div>
    </div>
    <div class="cell" style="">
    <p>① 给定 n个tokens, 记作x1, …,xn, 通过一个预训练模型对应的embedding table，可以将n个token表示为一个向量矩阵(Xe-&gt;Rn*e). </p><p>② 将连续模板中的每个伪标记vi视为参数，可以通过另一个embedding table获得p个伪token标记为向量矩阵(Pe-&gt;Rp*e). </p><p>③ 将文本和Prompt拼接获得新的输入[Pe:Xe]-&gt;R(p+n)*e. </p><p>④ 新的输入喂入一个MLP获得新的表征. 注意，只有prompt对应的向量表征参数(Pe-&gt;Rp*e) 会随着训练进行更新</p>
    </div>
    </div>
<h4 id="Prompt-Tuning方法特点"><a href="#Prompt-Tuning方法特点" class="headerlink" title="Prompt Tuning方法特点"></a>Prompt Tuning方法特点</h4><ul>
<li><strong>优点</strong><ul>
<li>大模型的微调新范式</li>
<li>模型参数规模大了之后，可以将大模型参数固定，指定附加参数来适配下游任务，而且适配性能基本和全参数微调相当</li>
</ul>
</li>
<li><strong>缺点</strong><ul>
<li>在小样本学习场景上表现不太行</li>
<li>收敛速度比较慢</li>
<li>调参比较复杂</li>
</ul>
</li>
</ul>
<h3 id="P-Tuning-V1（NLU任务）"><a href="#P-Tuning-V1（NLU任务）" class="headerlink" title="P-Tuning V1（NLU任务）"></a>P-Tuning V1（NLU任务）</h3><blockquote>
<p>P-Tuning 是2022年清华在论文《GPT Understands, Too》中提出的微调方法，P-Tuning V1方法的提出主要是为了解决</p>
<p>这样一个问题：大模型的 Prompt 构造方式严重影响下游任务的效果</p>
</blockquote>
<p><strong>P-Tuning 提出将 Prompt 转换为可以学习的 Embedding 层，只是考虑到直接对Embedding 参数进行优化</strong></p>
<p>P-Tuning V1 直接对 Embedding 参数进行优化会存在两个挑战：</p>
<ul>
<li>Discretenes(不连续性)： 对输入正常语料的 Embedding 层已经经过预训练，而如果直接对输入的 prompt embedding进行随机初始化训练，容易陷入局部最优</li>
<li>Association(关联性分析)：没法捕捉到 prompt embedding 之间的相关关系</li>
</ul>
<div class="tag-plugin image"><div class="image-bg" style="aspect-ratio:1019/560;"><img class="lazy" src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251125184610613.png" data-src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251125184610613.png" data-fancybox="true"onerror="this.src=&quot;data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='2rem' height='2rem' viewBox='0 0 24 24'%3E%3C!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --%3E%3Cpath fill='%23F44336' d='M22 12.698c-.002 1.47-.013 2.718-.096 3.743c-.097 1.19-.296 2.184-.74 3.009a4.2 4.2 0 0 1-.73.983c-.833.833-1.893 1.21-3.237 1.39C15.884 22 14.2 22 12.053 22h-.106c-2.148 0-3.83 0-5.144-.177c-1.343-.18-2.404-.557-3.236-1.39c-.738-.738-1.12-1.656-1.322-2.795c-.2-1.12-.236-2.512-.243-4.241Q1.999 12.737 2 12v-.054c0-2.148 0-3.83.177-5.144c.18-1.343.557-2.404 1.39-3.236s1.893-1.21 3.236-1.39c1.168-.157 2.67-.175 4.499-.177a.697.697 0 1 1 0 1.396c-1.855.002-3.234.018-4.313.163c-1.189.16-1.906.464-2.436.994S3.72 5.8 3.56 6.99C3.397 8.2 3.395 9.788 3.395 12v.784l.932-.814a2.14 2.14 0 0 1 2.922.097l3.99 3.99a1.86 1.86 0 0 0 2.385.207l.278-.195a2.79 2.79 0 0 1 3.471.209l2.633 2.37c.265-.557.423-1.288.507-2.32c.079-.972.09-2.152.091-3.63a.698.698 0 0 1 1.396 0' opacity='.5'/%3E%3Cpath fill='%23F44336' fill-rule='evenodd' d='M17.5 11c-2.121 0-3.182 0-3.841-.659S13 8.621 13 6.5s0-3.182.659-3.841S15.379 2 17.5 2s3.182 0 3.841.659S22 4.379 22 6.5s0 3.182-.659 3.841S19.621 11 17.5 11m-1.47-7.03a.75.75 0 1 0-1.06 1.06l1.47 1.47l-1.47 1.47a.75.75 0 0 0 1.06 1.06l1.47-1.47l1.47 1.47a.75.75 0 1 0 1.06-1.06L18.56 6.5l1.47-1.47a.75.75 0 0 0-1.06-1.06L17.5 5.44z' clip-rule='evenodd'/%3E%3C/svg%3E&quot;"/><div class="lazy-icon" style="background-image:url(https://api.iconify.design/eos-icons:three-dots-loading.svg?color=%231cd0fd);"></div></div></div>
<ul>
<li>用 MLP + LSTM 的方式来对 prompt embedding 进行一层处理</li>
<li>P-tuning 固定 LLM 参数, 利用多层感知机 (MLP)和LSTM 对 Prompt 进行编码，编码之后与其他向量进行拼接之后正常输入 LLM. 注意，训练之后只保留Prompt 编码之后的向量即可，无需保留编码器</li>
</ul>
<h4 id="对比Prompt-Tuning"><a href="#对比Prompt-Tuning" class="headerlink" title="对比Prompt Tuning"></a>对比Prompt Tuning</h4><ul>
<li>Prompt Tuning 是将额外的 embedding 加在开头，看起来更像是模仿Instruction 指令；而 P-Tuning 的位置则不固定</li>
<li>Prompt Tuning 不需要加入 MLP 来参数初始化；而 P-Tuning 通过 LSTM+MLP来初始化</li>
</ul>
<h3 id="P-Tuning-V2"><a href="#P-Tuning-V2" class="headerlink" title="P-Tuning V2"></a>P-Tuning V2</h3><blockquote>
<p>P-Tuning V2是升级版本，主要解决P-Tuning V1 在小参数量模型上表现差的问题</p>
</blockquote>
<div class="tag-plugin image"><div class="image-bg" style="aspect-ratio:2241/516;"><img class="lazy" src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251125185525516.png" data-src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251125185525516.png" data-fancybox="true"onerror="this.src=&quot;data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='2rem' height='2rem' viewBox='0 0 24 24'%3E%3C!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --%3E%3Cpath fill='%23F44336' d='M22 12.698c-.002 1.47-.013 2.718-.096 3.743c-.097 1.19-.296 2.184-.74 3.009a4.2 4.2 0 0 1-.73.983c-.833.833-1.893 1.21-3.237 1.39C15.884 22 14.2 22 12.053 22h-.106c-2.148 0-3.83 0-5.144-.177c-1.343-.18-2.404-.557-3.236-1.39c-.738-.738-1.12-1.656-1.322-2.795c-.2-1.12-.236-2.512-.243-4.241Q1.999 12.737 2 12v-.054c0-2.148 0-3.83.177-5.144c.18-1.343.557-2.404 1.39-3.236s1.893-1.21 3.236-1.39c1.168-.157 2.67-.175 4.499-.177a.697.697 0 1 1 0 1.396c-1.855.002-3.234.018-4.313.163c-1.189.16-1.906.464-2.436.994S3.72 5.8 3.56 6.99C3.397 8.2 3.395 9.788 3.395 12v.784l.932-.814a2.14 2.14 0 0 1 2.922.097l3.99 3.99a1.86 1.86 0 0 0 2.385.207l.278-.195a2.79 2.79 0 0 1 3.471.209l2.633 2.37c.265-.557.423-1.288.507-2.32c.079-.972.09-2.152.091-3.63a.698.698 0 0 1 1.396 0' opacity='.5'/%3E%3Cpath fill='%23F44336' fill-rule='evenodd' d='M17.5 11c-2.121 0-3.182 0-3.841-.659S13 8.621 13 6.5s0-3.182.659-3.841S15.379 2 17.5 2s3.182 0 3.841.659S22 4.379 22 6.5s0 3.182-.659 3.841S19.621 11 17.5 11m-1.47-7.03a.75.75 0 1 0-1.06 1.06l1.47 1.47l-1.47 1.47a.75.75 0 0 0 1.06 1.06l1.47-1.47l1.47 1.47a.75.75 0 1 0 1.06-1.06L18.56 6.5l1.47-1.47a.75.75 0 0 0-1.06-1.06L17.5 5.44z' clip-rule='evenodd'/%3E%3C/svg%3E&quot;"/><div class="lazy-icon" style="background-image:url(https://api.iconify.design/eos-icons:three-dots-loading.svg?color=%231cd0fd);"></div></div></div>
<p>P-Tuning v2 方法的核心思想：在模型的每一层都应用连续的 prompts, 并对 prompts 参数进行更新优化. 同时, 该方法也是针对 NLU 任务优化和适配的</p>
<h2 id="超大规模参数Prompt-Tuning方法"><a href="#超大规模参数Prompt-Tuning方法" class="headerlink" title="超大规模参数Prompt-Tuning方法"></a>超大规模参数Prompt-Tuning方法</h2><blockquote>
<p>近两年来，随着Prompt-Tuning技术的发展，对于超过10亿参数量的模型来说，Prompt-Tuning所带来的增益远远高于标准的Fine-tuning. 如GPT-3模型, 只需要设计合适的模板或指令即可以实现免参数训练的零样本学习</p>
<p>根本原因：模型参数量足够大，训练过程中使用了 足够多的语料，同时设计的 预训练任务足够有效</p>
</blockquote>
<h3 id="In-Context-Learing"><a href="#In-Context-Learing" class="headerlink" title="In-Context Learing"></a>In-Context Learing</h3><blockquote>
<p>上下文学习In-Context learning（ICL）最早在GPT3中提出, 旨在从训练集中挑选少量的标注样本，设计任务相关的指令形成提示模板，用于指导测试样本生成相应的结果</p>
</blockquote>
<p><strong>zero-shot learning</strong></p>
<ul>
<li>给出任务的描述, 然后提供测试数据对其进行预测, 直接让预训练好的模型去进行任务测试</li>
</ul>
<p><strong>one-shot learning</strong></p>
<ul>
<li>给出任务的描述, 在进行新数据预测前, 插入一个样本做指导，相当于给一个例子让模型理解，然后再提供测试数据对其进行预测</li>
</ul>
<p><strong>few-shot learning</strong></p>
<ul>
<li>给出任务的描述, 在进行新数据预测前, 插入N个样本做指导. 相当于给N个例子让模型理解, 然后再提供测试数据对其进行预测</li>
</ul>
<h3 id="Instruction-Learning"><a href="#Instruction-Learning" class="headerlink" title="Instruction Learning"></a>Instruction Learning</h3><blockquote>
<p>指令学习Instruction-Tuning和Prompt-Tuning的核心一样，就是去发掘语言模型本身具备的知识</p>
</blockquote>
<ul>
<li>其实Prompt-Tuning本质上是对下游任务的指令，简单的来说：就是告诉模型需要做什么任务，输出什么内容. 上文我们提及到的离散或连续的模板，本质上就是一种对任务的提示</li>
<li>因此, 在对大规模模型进行微调时, 可以为各种类型的任务定义指令, 并进行训练，来提高模型对不同任务的泛化能力</li>
</ul>
<div class="tag-plugin grid"  style="grid-template-columns: repeat(auto-fill, minmax(240px, 1fr));"><div class="cell" style="">
    <p><strong>Prompt</strong></p><p>带女朋友去了一家餐厅，她吃的很开心，餐厅，她吃的很开心， 这家餐厅太_了！</p>
    </div>
    <div class="cell" style="">
    <p><strong>Instruction</strong></p><p>判断这句话的情感：带女朋友去了一家餐厅，她吃的很开心。选项：A=好，B=一般， C=差</p>
    </div>
    </div>
<h4 id="对比Prompt"><a href="#对比Prompt" class="headerlink" title="对比Prompt"></a>对比Prompt</h4><ul>
<li>Prompt是去激发语言模型的补全能力，比如给出上半句生成下半句、或者做完形填空</li>
<li>Instruction-Tuning则是激发语言模型的理解能力，通过给出更明显的指令/指示，让模型去理解并做出正确的action</li>
<li>Promp-Tuningt在没有精调的模型上也能有一定效果，但是InstructTuning则必须对模型精调, 让模型知道这种指令模式</li>
</ul>
<h3 id="Chain-of-Thought"><a href="#Chain-of-Thought" class="headerlink" title="Chain-of-Thought"></a>Chain-of-Thought</h3><blockquote>
<p>思维链 (Chain-of-thought，CoT) 的概念是在 Google 的论文 “Chain-of-Thought Prompting Elicits Reasoning in Large Language Models” 中被首次提出</p>
</blockquote>
<ul>
<li>思维链（CoT）是一种改进的提示策略，用于提高 LLM 在复杂推理任务中的性能，如算术推理、常识推理和符号推理</li>
<li>思维链是一种离散式提示学习，更具体地，大模型下的上下文学习（即不进行训练，将例子添加到当前样本输入的前面，让模型一次输入这些文本进行输出完成任务），相比于之前传统的上下文学习（即通过x1,y1,x2,y2,….xtest）作为输入来让大模型补全输出test），思维链多了中间的推导提示</li>
</ul>
<p>用一个逻辑推理来简单理解什么是CoT</p>
<p>题目：</p>
<blockquote>
<p>桌上有三个盒子：红盒子、蓝盒子、绿盒子。<br> 红盒子里一定不是金币；蓝盒子可能有金币；<br> 如果绿盒子里没有金币，那么蓝盒子一定有金币。<br> 问：如果蓝盒子没有金币，金币在哪里？</p>
</blockquote>
<p><strong>不用思维链</strong></p>
<p>模型可能乱猜：</p>
<blockquote>
<p><strong>绿盒子</strong></p>
</blockquote>
<p><strong>用思维链</strong></p>
<p>让模型“说思考过程”：</p>
<blockquote>
<ol>
<li>假设蓝盒子没有金币</li>
<li>那么根据题意“若绿盒子没有金币，则蓝盒子一定有金币”，此时蓝盒子没有金币 → 绿盒子不可能没有</li>
<li>所以绿盒子里必须有金币</li>
<li>红盒子不可能有金币（题意说明）<br> <strong>因此金币在绿盒子里</strong></li>
</ol>
</blockquote>
<p>通过链式推理，模型能得到正确答案</p>
<h4 id="CoT分类"><a href="#CoT分类" class="headerlink" title="CoT分类"></a>CoT分类</h4><p><strong>Few-shot CoT</strong></p>
<ul>
<li>ICL 的一种特殊情况，它通过融合CoT 推理步骤，将每个演示〈input，output〉扩充为〈input,CoT,output〉</li>
</ul>
<p><strong>Zero-shot CoT</strong></p>
<ul>
<li>直接生成推理步骤，然后使用生成的 CoT来导出答案.（其中 LLM 首先由 “Let’sthink step by step” 提示生成推理步骤，然后由 “Therefore, the answer is” 提示得出最终答案。他们发现，当模型规模超过一定规模时，这种策略会大大提高性能，但对小规模模型无效，显示出显著的涌现能力模式）</li>
</ul>
<h2 id="PEFT"><a href="#PEFT" class="headerlink" title="PEFT"></a>PEFT</h2><blockquote>
<p><strong>PEFT（Parameter-Efficient Fine-Tuning）</strong>参数高效微调方法是目前大模型在工业界应用的主流方式之一，PEFT 方法仅微调少量或额外的模型参数，固定大部分预训练参数，大大降低了计算和存储成本，同时最先进的 PEFT 技术也能实现了与全量微调相当的性能</p>
</blockquote>
<p>PEFT的优势：</p>
<ul>
<li>该方法可以使 PLM 高效适应各种下游应用任务，而无需微调预训练模型的所有参数，且让大模型在消费级硬件上进行全量微调（Full Fine-Tuning）变得可行，这里的全量微调并不是真的全参数更新，只是能达到与之接近的效果</li>
</ul>
<h3 id="Prefix-Tuning"><a href="#Prefix-Tuning" class="headerlink" title="Prefix Tuning"></a>Prefix Tuning</h3><blockquote>
<p>2021年论文《Prefix-Tuning: Optimizing Continuous Prompts for Generation》中提出了 Prefix Tuning 方法，该方法是在输入 token 之前构造一段任务相关的 virtual tokens 作为 Prefix，然后训练的时候只更新 Prefix 部分的参数，而 Transformer 中的其他部分参数固定</p>
</blockquote>
<div class="tag-plugin image"><div class="image-bg" style="aspect-ratio:932/670;"><img class="lazy" src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251125214203658.png" data-src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251125214203658.png" data-fancybox="true"onerror="this.src=&quot;data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='2rem' height='2rem' viewBox='0 0 24 24'%3E%3C!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --%3E%3Cpath fill='%23F44336' d='M22 12.698c-.002 1.47-.013 2.718-.096 3.743c-.097 1.19-.296 2.184-.74 3.009a4.2 4.2 0 0 1-.73.983c-.833.833-1.893 1.21-3.237 1.39C15.884 22 14.2 22 12.053 22h-.106c-2.148 0-3.83 0-5.144-.177c-1.343-.18-2.404-.557-3.236-1.39c-.738-.738-1.12-1.656-1.322-2.795c-.2-1.12-.236-2.512-.243-4.241Q1.999 12.737 2 12v-.054c0-2.148 0-3.83.177-5.144c.18-1.343.557-2.404 1.39-3.236s1.893-1.21 3.236-1.39c1.168-.157 2.67-.175 4.499-.177a.697.697 0 1 1 0 1.396c-1.855.002-3.234.018-4.313.163c-1.189.16-1.906.464-2.436.994S3.72 5.8 3.56 6.99C3.397 8.2 3.395 9.788 3.395 12v.784l.932-.814a2.14 2.14 0 0 1 2.922.097l3.99 3.99a1.86 1.86 0 0 0 2.385.207l.278-.195a2.79 2.79 0 0 1 3.471.209l2.633 2.37c.265-.557.423-1.288.507-2.32c.079-.972.09-2.152.091-3.63a.698.698 0 0 1 1.396 0' opacity='.5'/%3E%3Cpath fill='%23F44336' fill-rule='evenodd' d='M17.5 11c-2.121 0-3.182 0-3.841-.659S13 8.621 13 6.5s0-3.182.659-3.841S15.379 2 17.5 2s3.182 0 3.841.659S22 4.379 22 6.5s0 3.182-.659 3.841S19.621 11 17.5 11m-1.47-7.03a.75.75 0 1 0-1.06 1.06l1.47 1.47l-1.47 1.47a.75.75 0 0 0 1.06 1.06l1.47-1.47l1.47 1.47a.75.75 0 1 0 1.06-1.06L18.56 6.5l1.47-1.47a.75.75 0 0 0-1.06-1.06L17.5 5.44z' clip-rule='evenodd'/%3E%3C/svg%3E&quot;"/><div class="lazy-icon" style="background-image:url(https://api.iconify.design/eos-icons:three-dots-loading.svg?color=%231cd0fd);"></div></div></div>
<p><strong>任务形式</strong></p>
<div class="tag-plugin image"><div class="image-bg" style="aspect-ratio:2133/946;"><img class="lazy" src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251125214842009.png" data-src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251125214842009.png" data-fancybox="true"onerror="this.src=&quot;data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='2rem' height='2rem' viewBox='0 0 24 24'%3E%3C!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --%3E%3Cpath fill='%23F44336' d='M22 12.698c-.002 1.47-.013 2.718-.096 3.743c-.097 1.19-.296 2.184-.74 3.009a4.2 4.2 0 0 1-.73.983c-.833.833-1.893 1.21-3.237 1.39C15.884 22 14.2 22 12.053 22h-.106c-2.148 0-3.83 0-5.144-.177c-1.343-.18-2.404-.557-3.236-1.39c-.738-.738-1.12-1.656-1.322-2.795c-.2-1.12-.236-2.512-.243-4.241Q1.999 12.737 2 12v-.054c0-2.148 0-3.83.177-5.144c.18-1.343.557-2.404 1.39-3.236s1.893-1.21 3.236-1.39c1.168-.157 2.67-.175 4.499-.177a.697.697 0 1 1 0 1.396c-1.855.002-3.234.018-4.313.163c-1.189.16-1.906.464-2.436.994S3.72 5.8 3.56 6.99C3.397 8.2 3.395 9.788 3.395 12v.784l.932-.814a2.14 2.14 0 0 1 2.922.097l3.99 3.99a1.86 1.86 0 0 0 2.385.207l.278-.195a2.79 2.79 0 0 1 3.471.209l2.633 2.37c.265-.557.423-1.288.507-2.32c.079-.972.09-2.152.091-3.63a.698.698 0 0 1 1.396 0' opacity='.5'/%3E%3Cpath fill='%23F44336' fill-rule='evenodd' d='M17.5 11c-2.121 0-3.182 0-3.841-.659S13 8.621 13 6.5s0-3.182.659-3.841S15.379 2 17.5 2s3.182 0 3.841.659S22 4.379 22 6.5s0 3.182-.659 3.841S19.621 11 17.5 11m-1.47-7.03a.75.75 0 1 0-1.06 1.06l1.47 1.47l-1.47 1.47a.75.75 0 0 0 1.06 1.06l1.47-1.47l1.47 1.47a.75.75 0 1 0 1.06-1.06L18.56 6.5l1.47-1.47a.75.75 0 0 0-1.06-1.06L17.5 5.44z' clip-rule='evenodd'/%3E%3C/svg%3E&quot;"/><div class="lazy-icon" style="background-image:url(https://api.iconify.design/eos-icons:three-dots-loading.svg?color=%231cd0fd);"></div></div></div>
<ul>
<li><p>Prefix-Tuning 在输入前添加前缀，即z=[Prefix,x,y] ，Pidx为前缀序列的索引, |Pidx|为前</p>
<p>缀的长度。前缀索引对应着由θ参数化的向量矩阵 Pθ, 维度为|Pidx|×dim(hi). </p>
</li>
<li><p>注意：由于直接更新 Prefix 的参数会导致训练不稳定，作者在 Prefix 层前面加了 MLP 结构(相当于将Prefix</p>
<p>分解为更小维度的 Input 与 MLP 的组合后输出的结果)，训练完成后，只保留 Prefix 的参数.</p>
</li>
</ul>
<p><strong>对比</strong></p>
<div class="tag-plugin grid"  style="grid-template-columns: repeat(auto-fill, minmax(240px, 1fr));"><div class="cell" style="">
    <h4 id="对比P-Tuning"><a href="#对比P-Tuning" class="headerlink" title="对比P-Tuning"></a>对比P-Tuning</h4><ul><li><p>Prefix-Tuning 是将额外的embedding加在开头，看起来更像</p><p>模仿Instruction指令，而PTuning 位置不固定.</p></li><li><p>Prefix-Tuning 通过在每个层都添加可训练参数，通过MLP初始化，</p><p>而P-Tuning只在输入的时候加入embedding, 并通过LSTM+MLP初始化.</p></li></ul>
    </div>
    <div class="cell" style="">
    <h4 id="对比Prompt-Tuning"><a href="#对比Prompt-Tuning" class="headerlink" title="对比Prompt-Tuning"></a>对比Prompt-Tuning</h4><ul><li><p>Prompt Tuning 方式可以看做是Prefix Tuning 的简化，只在输入层</p><p>加入 prompt tokens，并不需要加入MLP 进行调整来解决难训练的问题.</p></li></ul>
    </div>
    </div>
<h3 id="Adapter-Tuning"><a href="#Adapter-Tuning" class="headerlink" title="Adapter Tuning"></a>Adapter Tuning</h3><blockquote>
<p>2019年谷歌的研究人员首次在论文《Parameter-Efficient Transfer Learning for NLP》提出针对BERT 的 PEFT微调方式，拉开了 PEFT 研究的序幕</p>
</blockquote>
<p>不同于Prefix Tuning这类在输入前添加可训练 prompt参数，以少量参数适配下游任务，Adapter Tuning则是在预训练模型内部的网络层之间添加新的网络层或模块来适配下游任务. 当模型训练时，固定住原来预训练模型的参数不变，只对新增的 Adapter 结构进行微调</p>
<h4 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h4><div class="tag-plugin image"><div class="image-bg" style="aspect-ratio:999/902;"><img class="lazy" src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251126072728066.png" data-src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251126072728066.png" data-fancybox="true"onerror="this.src=&quot;data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='2rem' height='2rem' viewBox='0 0 24 24'%3E%3C!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --%3E%3Cpath fill='%23F44336' d='M22 12.698c-.002 1.47-.013 2.718-.096 3.743c-.097 1.19-.296 2.184-.74 3.009a4.2 4.2 0 0 1-.73.983c-.833.833-1.893 1.21-3.237 1.39C15.884 22 14.2 22 12.053 22h-.106c-2.148 0-3.83 0-5.144-.177c-1.343-.18-2.404-.557-3.236-1.39c-.738-.738-1.12-1.656-1.322-2.795c-.2-1.12-.236-2.512-.243-4.241Q1.999 12.737 2 12v-.054c0-2.148 0-3.83.177-5.144c.18-1.343.557-2.404 1.39-3.236s1.893-1.21 3.236-1.39c1.168-.157 2.67-.175 4.499-.177a.697.697 0 1 1 0 1.396c-1.855.002-3.234.018-4.313.163c-1.189.16-1.906.464-2.436.994S3.72 5.8 3.56 6.99C3.397 8.2 3.395 9.788 3.395 12v.784l.932-.814a2.14 2.14 0 0 1 2.922.097l3.99 3.99a1.86 1.86 0 0 0 2.385.207l.278-.195a2.79 2.79 0 0 1 3.471.209l2.633 2.37c.265-.557.423-1.288.507-2.32c.079-.972.09-2.152.091-3.63a.698.698 0 0 1 1.396 0' opacity='.5'/%3E%3Cpath fill='%23F44336' fill-rule='evenodd' d='M17.5 11c-2.121 0-3.182 0-3.841-.659S13 8.621 13 6.5s0-3.182.659-3.841S15.379 2 17.5 2s3.182 0 3.841.659S22 4.379 22 6.5s0 3.182-.659 3.841S19.621 11 17.5 11m-1.47-7.03a.75.75 0 1 0-1.06 1.06l1.47 1.47l-1.47 1.47a.75.75 0 0 0 1.06 1.06l1.47-1.47l1.47 1.47a.75.75 0 1 0 1.06-1.06L18.56 6.5l1.47-1.47a.75.75 0 0 0-1.06-1.06L17.5 5.44z' clip-rule='evenodd'/%3E%3C/svg%3E&quot;"/><div class="lazy-icon" style="background-image:url(https://api.iconify.design/eos-icons:three-dots-loading.svg?color=%231cd0fd);"></div></div></div>
<ul>
<li><p>首先是一个 down-project 层将高维度特征映射到低维特征. </p>
</li>
<li><p>然后过一个非线形层之后，再用一个 up-project 结构将低维特征映射回原来的高维特征</p>
</li>
<li><p>同时也设计了 skip-connection 结构，确保了在最差的情况下能够退化为identity（类似残差结构）</p>
</li>
</ul>
<h3 id="LoRA"><a href="#LoRA" class="headerlink" title="LoRA"></a>LoRA</h3><blockquote>
<p>低秩适应（Low-Rank Adaptation）是一种参数高效的微调技术，其核心思想是对大型模型的权重矩阵进行隐式的低秩转换，也就是：通过一个较低维度的表示来近似表示一个高维矩阵或数据集</p>
</blockquote>
<p><strong>LoRA的产生：</strong></p>
<ul>
<li>上述Adapter Tuning 方法在 PLM 基础上添加适配器层会引入额外的计算，带来推理延迟问题；而Prefix Tuning 方法难以优化，其性能随可训练参数规模非单调变化，更根本的是，为前缀保留部分序列长度必然会减少用于处理下游任务的序列长度. 因此微软推出了LoRA方法</li>
</ul>
<div class="tag-plugin grid"  style="grid-template-columns: repeat(auto-fill, minmax(240px, 1fr));"><div class="cell" style="">
    <div class="tag-plugin image"><div class="image-bg" style="aspect-ratio:887/818;"><img class="lazy" src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251126081006252.png" data-src="https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/20251126081006252.png" data-fancybox="true"onerror="this.src=&quot;data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='2rem' height='2rem' viewBox='0 0 24 24'%3E%3C!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --%3E%3Cpath fill='%23F44336' d='M22 12.698c-.002 1.47-.013 2.718-.096 3.743c-.097 1.19-.296 2.184-.74 3.009a4.2 4.2 0 0 1-.73.983c-.833.833-1.893 1.21-3.237 1.39C15.884 22 14.2 22 12.053 22h-.106c-2.148 0-3.83 0-5.144-.177c-1.343-.18-2.404-.557-3.236-1.39c-.738-.738-1.12-1.656-1.322-2.795c-.2-1.12-.236-2.512-.243-4.241Q1.999 12.737 2 12v-.054c0-2.148 0-3.83.177-5.144c.18-1.343.557-2.404 1.39-3.236s1.893-1.21 3.236-1.39c1.168-.157 2.67-.175 4.499-.177a.697.697 0 1 1 0 1.396c-1.855.002-3.234.018-4.313.163c-1.189.16-1.906.464-2.436.994S3.72 5.8 3.56 6.99C3.397 8.2 3.395 9.788 3.395 12v.784l.932-.814a2.14 2.14 0 0 1 2.922.097l3.99 3.99a1.86 1.86 0 0 0 2.385.207l.278-.195a2.79 2.79 0 0 1 3.471.209l2.633 2.37c.265-.557.423-1.288.507-2.32c.079-.972.09-2.152.091-3.63a.698.698 0 0 1 1.396 0' opacity='.5'/%3E%3Cpath fill='%23F44336' fill-rule='evenodd' d='M17.5 11c-2.121 0-3.182 0-3.841-.659S13 8.621 13 6.5s0-3.182.659-3.841S15.379 2 17.5 2s3.182 0 3.841.659S22 4.379 22 6.5s0 3.182-.659 3.841S19.621 11 17.5 11m-1.47-7.03a.75.75 0 1 0-1.06 1.06l1.47 1.47l-1.47 1.47a.75.75 0 0 0 1.06 1.06l1.47-1.47l1.47 1.47a.75.75 0 1 0 1.06-1.06L18.56 6.5l1.47-1.47a.75.75 0 0 0-1.06-1.06L17.5 5.44z' clip-rule='evenodd'/%3E%3C/svg%3E&quot;"/><div class="lazy-icon" style="background-image:url(https://api.iconify.design/eos-icons:three-dots-loading.svg?color=%231cd0fd);"></div></div></div>
    </div>
    <div class="cell" style="">
    <p>LoRA技术冻结预训练模型的权重，并在每个Transformer块</p><p>中注入可训练层（称为秩分解矩阵），即在模型的Linear</p><p>层的旁边增加一个“旁支”A和B。其中，A将数据从d维降</p><p>到r维，这个r是LoRA的秩，是一个重要的超参数；B将数据</p><p>从r维升到d维，B部分的参数初始为0。模型训练结束后，</p><p>需要将A+B部分的参数与原大模型的参数合并在一起使用</p>
    </div>
    </div>
<h2 id="PEFT发展时间线"><a href="#PEFT发展时间线" class="headerlink" title="PEFT发展时间线"></a>PEFT发展时间线</h2><div class="tag-plugin timeline"><div class="timenode" index="0"><div class="header"><span>2019 -- Adapter 系列（PEFT 的起点）</span></div><div class="body fs14"><blockquote><p><strong>● 2019.06 — Adapter-BERT</strong><br>论文：<em>Parameter-Efficient Transfer Learning for NLP</em>  </p><p>核心思想：  </p><ul><li>在 Transformer 每层插入一个小瓶颈网络（Adapter）  </li><li>冻结原模型，只训练 Adapter  </li></ul><p>影响：  </p><ul><li>开启“只训练少量参数”的 PEFT 思路  </li></ul><hr><p><strong>● 2019.12 — AdapterFusion</strong><br>论文：<em>AdapterFusion: Non-destructive Task Composition…</em>  </p><p>作用：  </p><ul><li>可以组合多个任务的 Adapter  </li><li>实现多任务知识融合  </li></ul></blockquote></div></div><div class="timenode" index="1"><div class="header"><span>2020 -- Prompt 化 + 连续 Prompt 开始出现</span></div><div class="body fs14"><blockquote><p><strong>● 2020.12 — Prompt Tuning（离散提示）</strong><br>背景：  </p><ul><li>GPT-3 展示了 Prompt Learning 的强大能力  </li><li>人工设计 Prompt 不稳定，激发对可训练提示的需求  </li></ul><p>意义：  </p><ul><li>连续 Prompt（Soft Prompt）的研究开始萌芽  </li></ul></blockquote></div></div><div class="timenode" index="2"><div class="header"><span>2021 -- Prompt 变成可训练向量（Soft Prompt 时代）</span></div><div class="body fs14"><blockquote><p><strong>● 2021.02 — GPT Prompt Tuning（Soft Prompt）</strong><br>论文：<em>The Power of Scale for Parameter-Efficient Prompt Tuning</em>  </p><p>创新：  </p><ul><li>引入可训练的 Prompt Embedding（虚拟 token）  </li><li>只训练几十个 embedding 即可完成新任务  </li></ul><p>意义：  </p><ul><li>计算成本极低  </li><li>Soft Prompt 方法正式确立  </li></ul><hr><p><strong>● 2021.04 — P-Tuning v1</strong><br>论文：<em>P-Tuning: Prompt Tuning Can Be Comparable to Finetuning</em>  </p><p>核心创新：  </p><ul><li>使用“可训练连续 embedding + LSTM”生成 Prompt  </li><li>在 BERT 类 encoder 模型上效果稳定  </li></ul><p>意义：  </p><ul><li>Soft Prompt 被扩展到更多模型  </li></ul><hr><p><strong>● 2021.09 — Prefix Tuning（Prefix-Tuning）</strong><br>论文：<em>Prefix-Tuning: Optimizing Continuous Prompts for Generation</em>  </p><p>特点：  </p><ul><li>给 Transformer 所有层加入训练前缀参数  </li><li>性能优于浅层 Soft Prompt  </li></ul><p>用途：  </p><ul><li>翻译、摘要、生成任务  </li></ul><hr><p><strong>● 2021.10 — P-Tuning v2</strong><br>论文：<em>P-Tuning v2: Prompt Tuning Can Be Comparable to FT on Large Models</em>  </p><p>特点：  </p><ul><li>Prefix Prompt + 深层结构统一框架  </li><li>性能接近 Full Fine-Tuning  </li><li>适配 GPT / BERT / T5  </li></ul><p>行业影响：  </p><ul><li>Prompt-based PEFT 的黄金版本  </li></ul></blockquote></div></div><div class="timenode" index="3"><div class="header"><span>2021-2022 -- 真正的大爆发：LoRA</span></div><div class="body fs14"><blockquote><p><strong>● 2021.12（发布）/2022.02（论文）— LoRA</strong><br>论文：<em>LoRA: Low-Rank Adaptation of Large Language Models</em>  </p><p>核心思想：  </p><ul><li>将权重增量参数化为低秩分解：W + BA  </li><li>冻结原模型，只训练 A、B  </li></ul><p>效果：  </p><ul><li>训练成本降低 100 倍  </li><li>性能接近全参数微调  </li></ul><p>意义：  </p><ul><li>LoRA 成为 LLM 时代最主流的 PEFT 方法  </li></ul></blockquote></div></div><div class="timenode" index="4"><div class="header"><span>2022 -- Prompt/Adapter/LoRA 多方法融合与优化</span></div><div class="body fs14"><blockquote><p><strong>● 2022.05 — IA3</strong><br>论文：<em>IA3: Efficient Adaptation of Pretrained Transformers</em>  </p><p>方法：  </p><ul><li>为每层仅加入缩放向量（gating-like）  </li><li>参数量比 LoRA 更小  </li></ul><hr><p><strong>● 2022.07 — 大模型（LLaMA/BLOOM/GLM）兴起</strong><br>影响：  </p><ul><li>LoRA 成为这些模型的事实标准微调方式  </li></ul></blockquote></div></div><div class="timenode" index="5"><div class="header"><span>2023 -- SFT 大模型时代，新型 PEFT</span></div><div class="body fs14"><blockquote><p><strong>● 2023.03 — QLoRA</strong><br>论文：<em>QLoRA: Efficient Finetuning of Quantized LLMs</em>  </p><p>创新：  </p><ul><li>在 4-bit 量化模型上使用 LoRA  </li><li>显著节省显存，同时保持 Full FT 性能  </li></ul><p>意义：  </p><ul><li>单卡 3090/A10 就能训练 7B/13B 模型  </li><li>PEFT 真正走向大众  </li></ul><hr><p><strong>● 2023.08 — PETL（PEFT）系统性综述</strong><br>论文：<em>Parameter-Efficient Transfer Learning: A Survey</em>  </p><p>意义：  </p><ul><li>首次完整整理所有 PEFT 方法  </li></ul></blockquote></div></div><div class="timenode" index="6"><div class="header"><span>2024 -- LLM 后时代的 PEFT 优化方向</span></div><div class="body fs14"><blockquote><p><strong>● 2024 — DoRA（Decomposition of Rank-3）</strong>  </p><ul><li>LoRA 改进版，分解矩阵 + 方向  </li><li>稳定性更高、训练更可控  </li></ul><hr><p><strong>● 2024 — AdaLoRA</strong>  </p><ul><li>动态调整 LoRA 的秩  </li><li>提升参数效率  </li></ul><hr><p><strong>● 2024 — LongLoRA</strong>  </p><ul><li>针对长上下文模型的 LoRA 改进  </li><li>大幅提升长序列训练表现  </li></ul></blockquote></div></div></div>
</article>
<div class="article-footer">
    <section id="license">
      <div class="header"><span>许可协议</span></div>
      <div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div>
    </section>
    


    <section id="share">
      <div class="header"><span>分享文章</span></div>
      <div class="body">
        <div class="link"><input class="copy-area" readonly="true" id="copy-link" value="https://bambooo.top/2024/10/11/prompttuning/" /></div>
        <div class="social-wrap dis-select"><a class="social share-item wechat" onclick="util.toggle(&quot;qrcode-wechat&quot;)"><img  src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/b32ef3da1162a.svg" /></a><a class="social share-item weibo" target="_blank" rel="external nofollow noopener noreferrer" href="https://service.weibo.com/share/share.php?url=https://bambooo.top/2024/10/11/prompttuning/&title=Prompt Tuning - 扳布屋&pics=https://blog-vanh.oss-cn-hangzhou.aliyuncs.com/image/clipboard-image-1763683273.png&summary=讲讲提示词微调"><img  src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/80c07e4dbb303.svg" /></a><a class="social share-item email" href="mailto:?subject=Prompt Tuning - 扳布屋&amp;body=https://bambooo.top/2024/10/11/prompttuning/"><img  src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/a1b00e20f425d.svg" /></a><a class="social share-item link" onclick="util.copy(&quot;copy-link&quot;, &quot;复制成功&quot;)"><img  src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/8411ed322ced6.svg" /></a></div>
        
        <div class="qrcode" id="qrcode-wechat" style="opacity:0;height:0">
          <img src="https://api.qrserver.com/v1/create-qr-code/?size=256x256&data=https://bambooo.top/2024/10/11/prompttuning/"/>
        </div>
        
      </div>
    </section>
    </div>

<div class="related-wrap" id="read-next"><section class="body"><div class="item" id="prev"><div class="note">较新文章</div><a href="/2025/03/20/flashattn/">Flash Attention</a></div><div class="item" id="next"><div class="note">较早文章</div><a href="/2024/05/21/front_matter/">完整front-matter字段</a></div></section></div>




  <div class="related-wrap md-text" id="comments">
    <section class='header cmt-title cap theme'>
      <p>快来参与讨论吧~</p>

    </section>
    <section class='body cmt-body twikoo'>
      

<div id="twikoo_container"><svg class="loading" style="vertical-align:middle;fill:currentColor;overflow:hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2709"><path d="M832 512c0-176-144-320-320-320V128c211.2 0 384 172.8 384 384h-64zM192 512c0 176 144 320 320 320v64C300.8 896 128 723.2 128 512h64z" p-id="2710"></path></svg></div>
    </section>
  </div>



<footer class="page-footer footnote"><hr><div class="sitemap" style="column-count:2;"><div class="sitemap-group"><span class="fs15">博客</span><a href="/">近期发布</a><a href="/categories/">分类</a><a href="/tags/">标签</a><a href="/archives/">归档</a></div><div class="sitemap-group"><span class="fs15">社交</span><a target="_blank" rel="noopener" href="https://xaoxuu.com">xaoxuu</a></div></div><div class="text"><p>赣ICP备2025076167 | 基于<a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.33.1">Stellar</a>创建<br>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处</p>
</div></footer>
<div class="main-mask" onclick="sidebar.dismiss()"></div></div><aside class="l_right">
<div class="widgets">



<widget class="widget-wrapper toc" id="data-toc" collapse="false"><div class="widget-header dis-select"><span class="name">本文目录</span><a class="cap-action" onclick="sidebar.toggleTOC()" ><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg></a></div><div class="widget-body"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#NLP%E4%BB%BB%E5%8A%A1%E5%9B%9B%E7%A7%8D%E8%8C%83%E5%BC%8F"><span class="toc-text">NLP任务四种范式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Fine-Tuning"><span class="toc-text">Fine-Tuning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Prompt-Tuning%E7%AE%80%E8%BF%B0"><span class="toc-text">Prompt-Tuning简述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B7%A5%E4%BD%9C%E8%BF%87%E7%A8%8B"><span class="toc-text">工作过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%91%E6%88%98"><span class="toc-text">挑战</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Prompt-Tuning%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B"><span class="toc-text">Prompt-Tuning发展历程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%BC%BB%E7%A5%96-%E2%80%94%E2%80%94-GPT3"><span class="toc-text">鼻祖 —— GPT3</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PET%E6%A8%A1%E5%9E%8B"><span class="toc-text">PET模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Prompt-Oriented-Fine-Tuning"><span class="toc-text">Prompt-Oriented Fine-Tuning</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Soft-Prompt%E7%90%86%E8%A7%A3"><span class="toc-text">Soft Prompt理解</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Prompt-Tuning%EF%BC%88NLG%E4%BB%BB%E5%8A%A1%EF%BC%89"><span class="toc-text">Prompt Tuning（NLG任务）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Prompt-Tuning%E6%96%B9%E6%B3%95%E7%89%B9%E7%82%B9"><span class="toc-text">Prompt Tuning方法特点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#P-Tuning-V1%EF%BC%88NLU%E4%BB%BB%E5%8A%A1%EF%BC%89"><span class="toc-text">P-Tuning V1（NLU任务）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94Prompt-Tuning"><span class="toc-text">对比Prompt Tuning</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#P-Tuning-V2"><span class="toc-text">P-Tuning V2</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B6%85%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%8F%82%E6%95%B0Prompt-Tuning%E6%96%B9%E6%B3%95"><span class="toc-text">超大规模参数Prompt-Tuning方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#In-Context-Learing"><span class="toc-text">In-Context Learing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Instruction-Learning"><span class="toc-text">Instruction Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94Prompt"><span class="toc-text">对比Prompt</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Chain-of-Thought"><span class="toc-text">Chain-of-Thought</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#CoT%E5%88%86%E7%B1%BB"><span class="toc-text">CoT分类</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PEFT"><span class="toc-text">PEFT</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Prefix-Tuning"><span class="toc-text">Prefix Tuning</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94P-Tuning"><span class="toc-text">对比P-Tuning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94Prompt-Tuning"><span class="toc-text">对比Prompt-Tuning</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Adapter-Tuning"><span class="toc-text">Adapter Tuning</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="toc-text">模型结构</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LoRA"><span class="toc-text">LoRA</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PEFT%E5%8F%91%E5%B1%95%E6%97%B6%E9%97%B4%E7%BA%BF"><span class="toc-text">PEFT发展时间线</span></a></li></ol></div><div class="widget-footer"><a class="top" onclick="util.scrollTop()"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="1.5"><path stroke-linejoin="round" d="m9 15.5l3-3l3 3m-6-4l3-3l3 3"/><path d="M7 3.338A9.95 9.95 0 0 1 12 2c5.523 0 10 4.477 10 10s-4.477 10-10 10S2 17.523 2 12c0-1.821.487-3.53 1.338-5"/></g></svg><span>回到顶部</span></a><a class="buttom" onclick="util.scrollComment()"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="1.5" d="M8 10.5h8M8 14h5.5M17 3.338A9.95 9.95 0 0 0 12 2C6.477 2 2 6.477 2 12c0 1.6.376 3.112 1.043 4.453c.178.356.237.763.134 1.148l-.595 2.226a1.3 1.3 0 0 0 1.591 1.592l2.226-.596a1.63 1.63 0 0 1 1.149.133A9.96 9.96 0 0 0 12 22c5.523 0 10-4.477 10-10c0-1.821-.487-3.53-1.338-5"/></svg><span>参与讨论</span></a></div></widget>
</div></aside><div class='float-panel'>
  <button type='button' style='display:none' class='laptop-only rightbar-toggle mobile' onclick='sidebar.rightbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg>
  </button>
  <button type='button' style='display:none' class='mobile-only leftbar-toggle mobile' onclick='sidebar.leftbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="1.5"><path d="M2 11c0-3.771 0-5.657 1.172-6.828C4.343 3 6.229 3 10 3h4c3.771 0 5.657 0 6.828 1.172C22 5.343 22 7.229 22 11v2c0 3.771 0 5.657-1.172 6.828C19.657 21 17.771 21 14 21h-4c-3.771 0-5.657 0-6.828-1.172C2 18.657 2 16.771 2 13z"/><path id="sep" stroke-linecap="round" d="M5.5 10h6m-5 4h4m4.5 7V3"/></g></svg>
  </button>
</div>
</div><div class="scripts">


<script type="text/javascript">
  window.canonical = {"originalHost":null,"officialHosts":["localhost"],"encoded":""};
  const ctx = {
    date_suffix: {
      just: `刚刚`,
      min: `分钟前`,
      hour: `小时前`,
      day: `天前`,
    },
    root : `/`,
    tag_plugins: {
      chat: Object.assign({"api":"https://siteinfo.listentothewind.cn/api/v1"}),
    }
  };

  // required plugins (only load if needs)
  if (`local_search`) {
    ctx.search = {};
    ctx.search.service = `local_search`;
    if (ctx.search.service == 'local_search') {
      let service_obj = Object.assign({}, `{"field":"all","path":"/search.json","content":true,"skip_search":[],"codeblock":true,"sort":"-date"}`);
      ctx.search[ctx.search.service] = service_obj;
    }
  }
  const def = {
    avatar: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/avatar/round/3442075.svg`,
    cover: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/cover/76b86c0226ffd.svg`,
    loading: `https://api.iconify.design/eos-icons:three-dots-loading.svg?color=%231cd0fd`,
  };
  const deps = {
    jquery: `https://gcore.jsdelivr.net/npm/jquery@3.7/dist/jquery.min.js`,
    marked: `https://gcore.jsdelivr.net/npm/marked@13.0/lib/marked.umd.min.js`,
    lazyload: `/%5Bobject%20Object%5D`
  }
  

</script>

<script type="text/javascript">
  
  function RunItem() {
    this.list = []; // 存放回调函数
    this.start = () => {
      for (var i = 0; i < this.list.length; i++) {
        this.list[i].run();
      }
    };
    this.push = (fn, name, setRequestAnimationFrame = true) => {
      let myfn = fn
      if (setRequestAnimationFrame) {
        myfn = () => {
          utils.requestAnimationFrame(fn)
        }
      }
      var f = new Item(myfn, name);
      this.list.push(f);
    };
    this.remove = (name) => {
      for (let index = 0; index < this.list.length; index++) {
        const e = this.list[index];
        if (e.name == name) {
          this.list.splice(index, 1);
        }
      }
    }
    // 构造一个可以run的对象
    function Item(fn, name) {
      // 函数名称
      this.name = name || fn.name;
      // run方法
      this.run = () => {
        try {
          fn()
        } catch (error) {
          console.log(error);
        }
      };
    }
  }

  const utils = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    css: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    js: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      if (src.startsWith('/')) {
        src = ctx.root + src.substring(1);
      }
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function () {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    jq: (fn) => {
      if (typeof jQuery === 'undefined') {
        utils.js(deps.jquery).then(fn)
      } else {
        fn()
      }
    },

    onLoading: (el) => {
      if (el) {
        $(el).append('<div class="loading-wrap"><svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" stroke-opacity=".3" d="M12 3C16.9706 3 21 7.02944 21 12C21 16.9706 16.9706 21 12 21C7.02944 21 3 16.9706 3 12C3 7.02944 7.02944 3 12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="1.3s" values="60;0"/></path><path stroke-dasharray="15" stroke-dashoffset="15" d="M12 3C16.9706 3 21 7.02944 21 12"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.3s" values="15;0"/><animateTransform attributeName="transform" dur="1.5s" repeatCount="indefinite" type="rotate" values="0 12 12;360 12 12"/></path></g></svg></div>');
      }
    },
    onLoadSuccess: (el) => {
      if (el) {
        $(el).find('.loading-wrap').remove();
      }
    },
    onLoadFailure: (el) => {
      if (el) {
        $(el).find('.loading-wrap svg').remove();
        $(el).find('.loading-wrap').append('<svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" d="M12 3L21 20H3L12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.5s" values="60;0"/></path><path stroke-dasharray="6" stroke-dashoffset="6" d="M12 10V14"><animate fill="freeze" attributeName="stroke-dashoffset" begin="0.6s" dur="0.2s" values="6;0"/></path></g><circle cx="12" cy="17" r="1" fill="currentColor" fill-opacity="0"><animate fill="freeze" attributeName="fill-opacity" begin="0.8s" dur="0.4s" values="0;1"/></circle></svg>');
        $(el).find('.loading-wrap').addClass('error');
      }
    },
    request: (el, url, callback, onFailure) => {
      const maxRetry = 3;
      let retryCount = 0;

      return new Promise((resolve, reject) => {
        const load = () => {
          utils.onLoading?.(el);

          let timedOut = false;
          const timeout = setTimeout(() => {
            timedOut = true;
            console.warn('[request] 超时:', url);

            if (++retryCount >= maxRetry) {
              utils.onLoadFailure?.(el);
              onFailure?.();
              reject('请求超时');
            } else {
              setTimeout(load, 1000);
            }
          }, 5000);

          fetch(url).then(resp => {
            if (timedOut) return;
            clearTimeout(timeout);

            if (!resp.ok) throw new Error('响应失败');
            return resp;
          }).then(data => {
            if (timedOut) return;
            utils.onLoadSuccess?.(el);
            callback(data);
            resolve(data);
          }).catch(err => {
            clearTimeout(timeout);
            console.warn('[request] 错误:', err);

            if (++retryCount >= maxRetry) {
              utils.onLoadFailure?.(el);
              onFailure?.();
              reject(err);
            } else {
              setTimeout(load, 1000);
            }
          });
        };

        load();
      });
    },
    requestWithoutLoading: (url, options = {}, maxRetry = 2, timeout = 5000) => {
      return new Promise((resolve, reject) => {
        let retryCount = 0;

        const tryRequest = () => {
          let timedOut = false;
          const timer = setTimeout(() => {
            timedOut = true;
            if (++retryCount > maxRetry) reject('timeout');
            else tryRequest();
          }, timeout);

          fetch(url, options)
            .then(resp => {
              clearTimeout(timer);
              if (!resp.ok) throw new Error('bad response');
              resolve(resp);
            })
            .catch(err => {
              clearTimeout(timer);
              if (++retryCount > maxRetry) reject(err);
              else setTimeout(tryRequest, 500);
            });
        };

        tryRequest();
      });
    },
    /********************** requestAnimationFrame ********************************/
    // 1、requestAnimationFrame 会把每一帧中的所有 DOM 操作集中起来，在一次重绘或回流中就完成，并且重绘或回流的时间间隔紧紧跟随浏览器的刷新频率，一般来说，这个频率为每秒60帧。
    // 2、在隐藏或不可见的元素中，requestAnimationFrame 将不会进行重绘或回流，这当然就意味着更少的的 cpu，gpu 和内存使用量。
    requestAnimationFrame: (fn) => {
      if (!window.requestAnimationFrame) {
        window.requestAnimationFrame = window.requestAnimationFrame || window.mozRequestAnimationFrame || window.webkitRequestAnimationFrame;
      }
      window.requestAnimationFrame(fn)
    },
    dark: {},
  };

  // utils.dark.mode 当前模式 dark or light
  // utils.dark.toggle() 暗黑模式触发器
  // utils.dark.push(callBack[,"callBackName"]) 传入触发器回调函数
  utils.dark.method = {
    toggle: new RunItem(),
  };
  utils.dark = Object.assign(utils.dark, {
    push: utils.dark.method.toggle.push,
  });
</script>
<script>
  const sidebar = {
    leftbar: () => {
      if (l_body) {
        l_body.toggleAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    rightbar: () => {
      if (l_body) {
        l_body.toggleAttribute('rightbar');
        l_body.removeAttribute('leftbar');
      }
    },
    dismiss: () => {
      if (l_body) {
        l_body.removeAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    toggleTOC: () => {
      document.querySelector('#data-toc').classList.toggle('collapse');
    }
  }
</script>
<script type="text/javascript">
  (() => {
    const tagSwitchers = document.querySelectorAll('.tag-subtree.parent-tag > a > .tag-switcher-wrapper')
    for (const tagSwitcher of tagSwitchers) {
      tagSwitcher.addEventListener('click', (e) => {
        const parent = e.target.closest('.tag-subtree.parent-tag')
        parent.classList.toggle('expanded')
        e.preventDefault()
      })
    }

    // Get active tag from query string, then activate it.
    const urlParams = new URLSearchParams(window.location.search)
    const activeTag = urlParams.get('tag')
    if (activeTag) {
      let tag = document.querySelector(`.tag-subtree[data-tag="${activeTag}"]`)
      if (tag) {
        tag.querySelector('a').classList.add('active')
        
        while (tag) {
          tag.classList.add('expanded')
          tag = tag.parentElement.closest('.tag-subtree.parent-tag')
        }
      }
    }
  })()
</script>

<script async src="https://gcore.jsdelivr.net/npm/vanilla-lazyload@19.1/dist/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazy",
    callback_loaded: (el) => {
      el.classList.add('loaded');
      const wrapper = el.closest('.lazy-box');
      const icon = wrapper?.querySelector('.lazy-icon');
      if (icon) icon.remove();
    }
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    window.lazyLoadInstance?.update();
  });

  window.wrapLazyloadImages = (container) => {
    if (typeof container === 'string') {
      container = document.querySelector(container);
    }
    if (!container) return;
    
    const images = container.querySelectorAll('img');
    images.forEach((img) => {
      if (img.classList.contains('lazy')) return;

      const src = img.getAttribute('src');
      if (!src) return;

      const wrapper = document.createElement('div');
      wrapper.className = 'lazy-box';

      const newImg = img.cloneNode();
      newImg.removeAttribute('src');
      newImg.setAttribute('data-src', src);
      newImg.classList.add('lazy');

      const icon = document.createElement('div');
      icon.className = 'lazy-icon';
      if (def.loading) {
        icon.style.backgroundImage = `url("${def.loading}")`;
      }

      wrapper.appendChild(newImg);
      wrapper.appendChild(icon);

      img.replaceWith(wrapper);
    });

    // 通知 LazyLoad 更新
    if (window.lazyLoadInstance?.update) {
      window.lazyLoadInstance.update();
    }
  }
  
</script>

<!-- required -->
<script src="/js/main.js?v=1.33.1" defer></script>

<script type="text/javascript">
  const applyTheme = (theme) => {
    if (theme === 'auto') {
      document.documentElement.removeAttribute('data-theme')
    } else {
      document.documentElement.setAttribute('data-theme', theme)
    }

    // applyThemeToGiscus(theme)
  }

  // FIXME: 这会导致无法使用 preferred_color_scheme 以外的主题
  const applyThemeToGiscus = (theme) => {
    // theme = theme === 'auto' ? 'preferred_color_scheme' : theme
    const cmt = document.getElementById('giscus')
    if (cmt) {
      // This works before giscus load.
      cmt.setAttribute('data-theme', theme)
    }

    const iframe = document.querySelector('#comments > section.giscus > iframe')
    if (iframe) {
      // This works after giscus loaded.
      const src = iframe.src
      const newSrc = src.replace(/theme=[\w]+/, `theme=${theme}`)
      iframe.src = newSrc
    }
  }

  const switchTheme = () => {
    // light -> dark -> auto -> light -> ...
    const currentTheme = document.documentElement.getAttribute('data-theme')
    let newTheme;
    switch (currentTheme) {
      case 'light':
        newTheme = 'dark'
        break
      case 'dark':
        newTheme = 'auto'
        break
      default:
        newTheme = 'light'
    }
    applyTheme(newTheme)
    window.localStorage.setItem('Stellar.theme', newTheme)
    utils.dark.mode = newTheme === 'auto' ? (window.matchMedia("(prefers-color-scheme: dark)").matches ? "dark" : "light") : newTheme;
    utils.dark.method.toggle.start();

    const messages = {
      light: `切换到浅色模式`,
      dark: `切换到深色模式`,
      auto: `切换到跟随系统配色`,
    }
    hud?.toast?.(messages[newTheme])
  }

  (() => {
    // Apply user's preferred theme, if any.
    const theme = window.localStorage.getItem('Stellar.theme')
    if (theme !== null) {
      applyTheme(theme)
    } else {
      utils.dark.mode = window.matchMedia("(prefers-color-scheme: dark)").matches ? "dark" : "light";
    }
    utils.dark.method.toggle.start();
  })()
</script>


<!-- optional -->

  <script type="module">
  const el = document.getElementById('twikoo_container');
  util.viewportLazyload(el, load_twikoo, false);

  function load_twikoo() {
    if (!el) return;
    utils.js('https://cdn.jsdelivr.net/npm/twikoo@1.6.44/dist/twikoo.min.js', {defer: true}).then(function () {
      const path = el.getAttribute('comment_id') ?? decodeURI(window.location.pathname);
      twikoo.init(Object.assign({"js":"https://cdn.jsdelivr.net/npm/twikoo@1.6.44/dist/twikoo.min.js","envId":"https://twikoo.bambooo.top"}, {
        el: '#twikoo_container',
        path: path,
      }));
    });
  }
</script>



<script defer>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.services = Object.assign({}, JSON.parse(`{"mdrender":{"js":"/js/services/mdrender.js"},"siteinfo":{"js":"/js/services/siteinfo.js","api":null},"ghinfo":{"js":"/js/services/ghinfo.js"},"rating":{"js":"/js/services/rating.js","api":"https://star-vote.xaox.cc/api/rating"},"vote":{"js":"/js/services/vote.js","api":"https://star-vote.xaox.cc/api/vote"},"sites":{"js":"/js/services/sites.js"},"friends":{"js":"/js/services/friends.js"},"friends_and_posts":{"js":"/js/services/friends_and_posts.js"},"timeline":{"js":"/js/services/timeline.js"},"fcircle":{"js":"/js/services/fcircle.js"},"weibo":{"js":"/js/services/weibo.js"},"memos":{"js":"/js/services/memos.js"},"voice":{"js":"/js/plugins/voice.js"},"video":{"js":"/js/plugins/video.js"},"download-file":{"js":"/js/plugins/download-file.js"},"twikoo":{"js":"/js/services/twikoo_latest_comment.js"},"waline":{"js":"/js/services/waline_latest_comment.js"},"artalk":{"js":"/js/services/artalk_latest_comment.js"},"giscus":{"js":"/js/services/giscus_latest_comment.js"},"contributors":{"edit_this_page":{"_posts/":null,"wiki/stellar/":"https://github.com/xaoxuu/hexo-theme-stellar-docs/blob/main/"},"js":"/js/services/contributors.js"}}`));
    for (let id of Object.keys(ctx.services)) {
      const js = ctx.services[id].js;
      if (id == 'siteinfo') {
        ctx.cardlinks = document.querySelectorAll('a.link-card[cardlink]');
        if (ctx.cardlinks?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            setCardLink(ctx.cardlinks);
          });
        }
      } else if (id == 'voice') {
        ctx.voiceAudios = document.querySelectorAll('.voice>audio');
        if (ctx.voiceAudios?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            createVoiceDom(ctx.voiceAudios);
          });
        }
      } else if (id == 'video') {
        ctx.videos = document.querySelectorAll('.video>video');
        if (ctx.videos?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            videoEvents(ctx.videos);
          });
        }
      } else if (id == 'download-file') {
        ctx.files = document.querySelectorAll('.file');
        if (ctx.files?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            downloadFileEvent(ctx.files);
          });
        }
      } else {
        const els = document.getElementsByClassName(`ds-${id}`);
        if (els?.length > 0) {
          utils.jq(() => {
            if (id == 'timeline' || 'memos' || 'marked') {
              utils.js(deps.marked).then(function () {
                utils.js(js, { defer: true });
              });
            } else {
              utils.js(js, { defer: true });
            }
          });
        }
      }
    }

    // chat iphone time
    let phoneTimes = document.querySelectorAll('.chat .status-bar .time');

    if (phoneTimes.length > 0) {
      NowTime();
      var date = new Date();
      var sec = date.getSeconds();
      var firstAdjustInterval = setInterval(firstAdjustTime, 1000 * (60 - sec));
    }

    function firstAdjustTime() {
      NowTime();
      clearInterval(firstAdjustInterval);
      setInterval(NowTime, 1000 * 60);
    }

    function NowTime() {
      for (let i = 0; i < phoneTimes.length; ++i) {
        var timeSpan = phoneTimes[i];
        var date = new Date();
        var hour = date.getHours();
        var min = date.getMinutes();
        timeSpan.innerHTML = check(hour) + ":" + check(min);
      }
    };

    function check(val) {
      if (val < 10) {
        return ("0" + val);
      }
      return (val);
    }

    // chat quote
    const chat_quote_obverser = new IntersectionObserver((entries, observer) => {
      entries.filter((entry) => { return entry.isIntersecting }).sort((a, b) => a.intersectionRect.y !== b.intersectionRect.y ? a.intersectionRect.y - b.intersectionRect.y : a.intersectionRect.x - b.intersectionRect.x).forEach((entry, index) => {
          observer.unobserve(entry.target);
          setTimeout(() => {
            entry.target.classList.add('quote-blink');
            setTimeout(() => {
              entry.target.classList.remove('quote-blink');
            }, 1000);
          }, Math.max(100, 16) * (index + 1));
        });
    });

    var chatQuotes = document.querySelectorAll(".chat .talk .quote");
    chatQuotes.forEach((quote) => {
      quote.addEventListener('click', function () {
        var chatCellDom = document.getElementById("quote-" + quote.getAttribute("quotedCellTag"));
        if (chatCellDom) {
          var chatDiv = chatCellDom.parentElement;
          var mid = chatDiv.clientHeight / 2;
          var offsetTop = chatCellDom.offsetTop;
          if (offsetTop > mid - chatCellDom.clientHeight / 2) {
            chatDiv.scrollTo({
              top: chatCellDom.offsetTop - mid + chatCellDom.clientHeight / 2,
              behavior: "smooth"
            });
          } else {
            chatDiv.scrollTo({
              top: 0,
              behavior: "smooth"
            });
          }
          chat_quote_obverser.observe(chatCellDom);
        }
      });
    });
  });
</script>

<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.search = {
      path: `/search.json`,
    }
    utils.js('/js/search/local-search.js', { defer: true });
  });
</script><script>
  window.FPConfig = {
    delay: 0,
    ignoreKeywords: [],
    maxRPS: 5,
    hoverDelay: 25
  };
</script>
<script defer src="https://gcore.jsdelivr.net/npm/flying-pages@2/flying-pages.min.js"></script><script>
  ctx.fancybox = {
    selector: `.timenode p>img`,
    css: `https://gcore.jsdelivr.net/npm/@fancyapps/ui@5.0/dist/fancybox/fancybox.css`,
    js: `https://gcore.jsdelivr.net/npm/@fancyapps/ui@5.0/dist/fancybox/fancybox.umd.js`
  };
  var selector = '[data-fancybox]:not(.error), .with-fancybox .atk-content img:not([atk-emoticon])';
  if (ctx.fancybox.selector) {
    selector += `, ${ctx.fancybox.selector}`
  }
  var needFancybox = document.querySelectorAll(selector).length !== 0;
  if (!needFancybox) {
    const memos = document.getElementsByClassName('ds-memos');
    if (memos != undefined && memos.length > 0) {
      needFancybox = true;
    }
    const fancybox = document.getElementsByClassName('with-fancybox');
    if (fancybox != undefined && fancybox.length > 0) {
      needFancybox = true;
    }
  }
  if (needFancybox) {
    utils.css(ctx.fancybox.css);
    utils.js(ctx.fancybox.js, { defer: true }).then(function () {
      Fancybox.bind(selector, {
        hideScrollbar: false,
        Thumbs: {
          autoStart: false,
        },
        caption: (fancybox, slide) => {
          return slide.triggerEl.alt || slide.triggerEl.dataset.caption || null
        }
      });
    })
  }
</script>
<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    const swiper_api = document.getElementById('swiper-api');
    if (swiper_api != undefined) {
      utils.css(`https://unpkg.com/swiper@10.3/swiper-bundle.min.css`);
      utils.js(`https://unpkg.com/swiper@10.3/swiper-bundle.min.js`, { defer: true }).then(function () {
        const effect = swiper_api.getAttribute('effect') || '';
        var swiper = new Swiper('.swiper#swiper-api', {
          slidesPerView: 'auto',
          spaceBetween: 8,
          centeredSlides: true,
          effect: effect,
          rewind: true,
          pagination: {
            el: '.swiper-pagination',
            clickable: true,
          },
          navigation: {
            nextEl: '.swiper-button-next',
            prevEl: '.swiper-button-prev',
          },
        });
      })
    }
  });
</script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.23/dist/katex.min.css" integrity="sha384-//SZkxyB7axjCAopkAL1E1rve+ZSPKapD89Lo/lLhcsXR+zOYl5z6zJZEFXil+q0" crossorigin="anonymous">

<script id="MathJax-script" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script defer type="text/javascript" src="https://gcore.jsdelivr.net/npm/mermaid@v9/dist/mermaid.min.js"></script>
<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    var mermaid_config = {
      startOnLoad: true,
      theme:
        "dark" == "auto" &&
          window.matchMedia("(prefers-color-scheme: dark)").matches
          ? "dark"
          : "neutral",
      logLevel: 3,
      themeVariables: {
        darkMode: true
      },
      flowchart: {
        useMaxWidth: false,
        htmlLabels: true,
        curve: "linear"
      },
      gantt: {
        axisFormat: "%Y/%m/%d"
      },
      sequence: {
        actorMargin: 50
      }
    }
    mermaid.initialize(mermaid_config);
  });
</script><script>
  document.addEventListener('DOMContentLoaded', function () {
    window.codeElements = document.querySelectorAll('.code');
    if (window.codeElements.length > 0) {
      ctx.copycode = {
        default_text: `Copy`,
        success_text: `Copied`,
        toast: `复制成功`,
      };
      utils.js('/js/plugins/copycode.js');
    }
  });
</script>


<!-- inject -->
<script type="text/javascript" src="/custom/js/BBDark.js"></script><script type="text/javascript" src="/custom/js/ai-summary.js"></script><script type="text/javascript" src="/custom/js/news-loader.js"></script>
</div></body></html>
